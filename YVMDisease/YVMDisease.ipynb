{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385ccba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3f89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'../HelperFunctions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db4e3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataHelper as dh\n",
    "import AugHelper as ah\n",
    "import ModelConfigHelper as mch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e88c1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from YVMModel import YVMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2cea970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YVMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de13e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the root directory of the file path -> C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yellow Mosaic\\dataset\\archive(7)\\data-resize\\train\n"
     ]
    }
   ],
   "source": [
    "path_info = dh.getFileDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "564baaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dh.getDataFrame(pathInfo=path_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ab1a8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>label</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                imgPath               label  \\\n",
       "0     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "1     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "2     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "3     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "4     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "...                                                 ...                 ...   \n",
       "1582  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "1583  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "1584  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "1585  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "1586  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "\n",
       "     augmentation  \n",
       "0          normal  \n",
       "1          normal  \n",
       "2          normal  \n",
       "3          normal  \n",
       "4          normal  \n",
       "...           ...  \n",
       "1582       normal  \n",
       "1583       normal  \n",
       "1584       normal  \n",
       "1585       normal  \n",
       "1586       normal  \n",
       "\n",
       "[1587 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "340392c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "diseased okra leaf :-\n",
      "885\n",
      "============================================\n",
      "fresh okra leaf :-\n",
      "702\n"
     ]
    }
   ],
   "source": [
    "dh.showFileCount(pathInfo=path_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d422318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the root directory of the file path -> C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yellow Mosaic\\dataset\\archive(7)\\data-resize\\val\n"
     ]
    }
   ],
   "source": [
    "path_info = dh.getFileDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7751b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "diseased okra leaf :-\n",
      "143\n",
      "============================================\n",
      "fresh okra leaf :-\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "dh.showFileCount(path_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c5fc8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = dh.getDataFrame(pathInfo=path_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b382551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>label</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>diseased okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>fresh okra leaf</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               imgPath               label  \\\n",
       "0    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "1    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "2    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "3    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "4    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "..                                                 ...                 ...   \n",
       "269  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "270  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "271  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...  diseased okra leaf   \n",
       "272  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "273  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...     fresh okra leaf   \n",
       "\n",
       "    augmentation  \n",
       "0         normal  \n",
       "1         normal  \n",
       "2         normal  \n",
       "3         normal  \n",
       "4         normal  \n",
       "..           ...  \n",
       "269       normal  \n",
       "270       normal  \n",
       "271       normal  \n",
       "272       normal  \n",
       "273       normal  \n",
       "\n",
       "[274 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "142e2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictlabel = dh.getLabelDicts(df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d974863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dh.dfPreProcess(df=train_df)\n",
    "val_df = dh.dfPreProcess(df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "064294f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>ylabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                imgPath augmentation  ylabel\n",
       "0     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "1     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "2     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "3     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "4     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "...                                                 ...          ...     ...\n",
       "1582  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "1583  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "1584  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "1585  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "1586  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "\n",
       "[1587 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d423fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>ylabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               imgPath augmentation  ylabel\n",
       "0    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "1    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "2    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "3    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "4    C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "..                                                 ...          ...     ...\n",
       "269  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "270  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "271  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       0\n",
       "272  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "273  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...       normal       1\n",
       "\n",
       "[274 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "747460ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diseased okra leaf', 'fresh okra leaf'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b36b6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTransform = ah.getImageTransform(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5773fcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "af45667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augDict = ah.getAugmentation(augmentRequired=True,augmentPolicies=[ah.transforms.AutoAugmentPolicy.IMAGENET],angle=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddd5e728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hFlip': RandomHorizontalFlip(p=1),\n",
       " 'vFlip': RandomVerticalFlip(p=1),\n",
       " 'rot': RandomRotation(degrees=[-90.0, 90.0], interpolation=nearest, expand=False, fill=0),\n",
       " 'aug0': AutoAugment(policy=AutoAugmentPolicy.IMAGENET, fill=None)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7378fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ah.augmentDataFrame(df=train_df,augDict=augDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a225d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>ylabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>hFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>vFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>hFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>vFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>vFlip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>hFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>hFlip</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>vFlip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>aug0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...</td>\n",
       "      <td>hFlip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7935 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                imgPath augmentation  ylabel\n",
       "0     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        hFlip       0\n",
       "1     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        vFlip       0\n",
       "2     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        hFlip       0\n",
       "3     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        vFlip       0\n",
       "4     C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        vFlip       1\n",
       "...                                                 ...          ...     ...\n",
       "7930  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        hFlip       0\n",
       "7931  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        hFlip       0\n",
       "7932  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        vFlip       1\n",
       "7933  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...         aug0       1\n",
       "7934  C:\\Users\\user\\Desktop\\ML\\PyTorch\\Hackathon\\Yel...        hFlip       1\n",
       "\n",
       "[7935 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "202ff342",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ah.KroniaDataset(data=train_df,transforms=imgTransform)\n",
    "val_ds = ah.KroniaDataset(data=val_df,transforms=imgTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e16e240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0615eb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YVMModel(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=18432, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b50d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset=train_ds,batch_size=32,shuffle=True)\n",
    "val_dl = DataLoader(dataset=val_ds,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d786d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x205e155b790>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b453e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05471774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= New Epoch =========================\n",
      "epoch:  0  batch:    2 [    64/7935]  loss: 0.75849581      accuracy:  48.438%\n",
      "epoch:  0  batch:    4 [   128/7935]  loss: 0.68432945      accuracy:  48.438%\n",
      "epoch:  0  batch:    6 [   192/7935]  loss: 0.68996471      accuracy:  48.438%\n",
      "epoch:  0  batch:    8 [   256/7935]  loss: 0.68485767      accuracy:  49.609%\n",
      "epoch:  0  batch:   10 [   320/7935]  loss: 0.64991438      accuracy:  55.625%\n",
      "epoch:  0  batch:   12 [   384/7935]  loss: 0.58946180      accuracy:  59.635%\n",
      "epoch:  0  batch:   14 [   448/7935]  loss: 0.55980891      accuracy:  59.598%\n",
      "epoch:  0  batch:   16 [   512/7935]  loss: 0.49468797      accuracy:  61.133%\n",
      "epoch:  0  batch:   18 [   576/7935]  loss: 0.41514039      accuracy:  61.979%\n",
      "epoch:  0  batch:   20 [   640/7935]  loss: 0.45992950      accuracy:  63.750%\n",
      "epoch:  0  batch:   22 [   704/7935]  loss: 0.43163079      accuracy:  65.199%\n",
      "epoch:  0  batch:   24 [   768/7935]  loss: 0.58881968      accuracy:  65.495%\n",
      "epoch:  0  batch:   26 [   832/7935]  loss: 0.62020397      accuracy:  65.625%\n",
      "epoch:  0  batch:   28 [   896/7935]  loss: 0.36784989      accuracy:  66.406%\n",
      "epoch:  0  batch:   30 [   960/7935]  loss: 0.42035434      accuracy:  66.979%\n",
      "epoch:  0  batch:   32 [  1024/7935]  loss: 0.47486314      accuracy:  67.969%\n",
      "epoch:  0  batch:   34 [  1088/7935]  loss: 0.42101330      accuracy:  68.382%\n",
      "epoch:  0  batch:   36 [  1152/7935]  loss: 0.39187837      accuracy:  69.097%\n",
      "epoch:  0  batch:   38 [  1216/7935]  loss: 0.28793898      accuracy:  69.984%\n",
      "epoch:  0  batch:   40 [  1280/7935]  loss: 0.39004543      accuracy:  70.781%\n",
      "epoch:  0  batch:   42 [  1344/7935]  loss: 0.26882118      accuracy:  71.503%\n",
      "epoch:  0  batch:   44 [  1408/7935]  loss: 0.24344110      accuracy:  72.159%\n",
      "epoch:  0  batch:   46 [  1472/7935]  loss: 0.38568628      accuracy:  72.554%\n",
      "epoch:  0  batch:   48 [  1536/7935]  loss: 0.26441473      accuracy:  73.438%\n",
      "epoch:  0  batch:   50 [  1600/7935]  loss: 0.28630063      accuracy:  73.938%\n",
      "epoch:  0  batch:   52 [  1664/7935]  loss: 0.14436191      accuracy:  74.639%\n",
      "epoch:  0  batch:   54 [  1728/7935]  loss: 0.25667816      accuracy:  75.231%\n",
      "epoch:  0  batch:   56 [  1792/7935]  loss: 0.30955276      accuracy:  75.781%\n",
      "epoch:  0  batch:   58 [  1856/7935]  loss: 0.34544858      accuracy:  76.239%\n",
      "epoch:  0  batch:   60 [  1920/7935]  loss: 0.31215984      accuracy:  76.771%\n",
      "epoch:  0  batch:   62 [  1984/7935]  loss: 0.45142105      accuracy:  77.117%\n",
      "epoch:  0  batch:   64 [  2048/7935]  loss: 0.09594902      accuracy:  77.686%\n",
      "epoch:  0  batch:   66 [  2112/7935]  loss: 0.15163527      accuracy:  77.983%\n",
      "epoch:  0  batch:   68 [  2176/7935]  loss: 0.21794276      accuracy:  78.447%\n",
      "epoch:  0  batch:   70 [  2240/7935]  loss: 0.09176839      accuracy:  78.929%\n",
      "epoch:  0  batch:   72 [  2304/7935]  loss: 0.25098160      accuracy:  79.297%\n",
      "epoch:  0  batch:   74 [  2368/7935]  loss: 0.15281886      accuracy:  79.603%\n",
      "epoch:  0  batch:   76 [  2432/7935]  loss: 0.30976355      accuracy:  79.852%\n",
      "epoch:  0  batch:   78 [  2496/7935]  loss: 0.34695286      accuracy:  80.048%\n",
      "epoch:  0  batch:   80 [  2560/7935]  loss: 0.10437636      accuracy:  80.469%\n",
      "epoch:  0  batch:   82 [  2624/7935]  loss: 0.22081810      accuracy:  80.716%\n",
      "epoch:  0  batch:   84 [  2688/7935]  loss: 0.13219115      accuracy:  81.064%\n",
      "epoch:  0  batch:   86 [  2752/7935]  loss: 0.12789240      accuracy:  81.432%\n",
      "epoch:  0  batch:   88 [  2816/7935]  loss: 0.23363388      accuracy:  81.712%\n",
      "epoch:  0  batch:   90 [  2880/7935]  loss: 0.22357900      accuracy:  81.979%\n",
      "epoch:  0  batch:   92 [  2944/7935]  loss: 0.26033214      accuracy:  82.201%\n",
      "epoch:  0  batch:   94 [  3008/7935]  loss: 0.12149584      accuracy:  82.547%\n",
      "epoch:  0  batch:   96 [  3072/7935]  loss: 0.17674161      accuracy:  82.812%\n",
      "epoch:  0  batch:   98 [  3136/7935]  loss: 0.44934717      accuracy:  82.844%\n",
      "epoch:  0  batch:  100 [  3200/7935]  loss: 0.35893327      accuracy:  82.938%\n",
      "epoch:  0  batch:  102 [  3264/7935]  loss: 0.13692489      accuracy:  83.180%\n",
      "epoch:  0  batch:  104 [  3328/7935]  loss: 0.07433609      accuracy:  83.383%\n",
      "epoch:  0  batch:  106 [  3392/7935]  loss: 0.18736748      accuracy:  83.520%\n",
      "epoch:  0  batch:  108 [  3456/7935]  loss: 0.17331114      accuracy:  83.681%\n",
      "epoch:  0  batch:  110 [  3520/7935]  loss: 0.12866713      accuracy:  83.920%\n",
      "epoch:  0  batch:  112 [  3584/7935]  loss: 0.18714477      accuracy:  84.040%\n",
      "epoch:  0  batch:  114 [  3648/7935]  loss: 0.18266770      accuracy:  84.211%\n",
      "epoch:  0  batch:  116 [  3712/7935]  loss: 0.15707162      accuracy:  84.375%\n",
      "epoch:  0  batch:  118 [  3776/7935]  loss: 0.09577438      accuracy:  84.587%\n",
      "epoch:  0  batch:  120 [  3840/7935]  loss: 0.16097137      accuracy:  84.583%\n",
      "epoch:  0  batch:  122 [  3904/7935]  loss: 0.12235440      accuracy:  84.708%\n",
      "epoch:  0  batch:  124 [  3968/7935]  loss: 0.15573561      accuracy:  84.803%\n",
      "epoch:  0  batch:  126 [  4032/7935]  loss: 0.27872846      accuracy:  84.921%\n",
      "epoch:  0  batch:  128 [  4096/7935]  loss: 0.30582646      accuracy:  85.010%\n",
      "epoch:  0  batch:  130 [  4160/7935]  loss: 0.18226820      accuracy:  85.144%\n",
      "epoch:  0  batch:  132 [  4224/7935]  loss: 0.13901295      accuracy:  85.275%\n",
      "epoch:  0  batch:  134 [  4288/7935]  loss: 0.16232219      accuracy:  85.424%\n",
      "epoch:  0  batch:  136 [  4352/7935]  loss: 0.41073316      accuracy:  85.455%\n",
      "epoch:  0  batch:  138 [  4416/7935]  loss: 0.12255304      accuracy:  85.530%\n",
      "epoch:  0  batch:  140 [  4480/7935]  loss: 0.03461757      accuracy:  85.692%\n",
      "epoch:  0  batch:  142 [  4544/7935]  loss: 0.04478965      accuracy:  85.893%\n",
      "epoch:  0  batch:  144 [  4608/7935]  loss: 0.23427619      accuracy:  85.959%\n",
      "epoch:  0  batch:  146 [  4672/7935]  loss: 0.13231397      accuracy:  86.045%\n",
      "epoch:  0  batch:  148 [  4736/7935]  loss: 0.30139822      accuracy:  86.106%\n",
      "epoch:  0  batch:  150 [  4800/7935]  loss: 0.11626697      accuracy:  86.229%\n",
      "epoch:  0  batch:  152 [  4864/7935]  loss: 0.18633713      accuracy:  86.308%\n",
      "epoch:  0  batch:  154 [  4928/7935]  loss: 0.05810568      accuracy:  86.445%\n",
      "epoch:  0  batch:  156 [  4992/7935]  loss: 0.05844665      accuracy:  86.619%\n",
      "epoch:  0  batch:  158 [  5056/7935]  loss: 0.25603831      accuracy:  86.689%\n",
      "epoch:  0  batch:  160 [  5120/7935]  loss: 0.08946972      accuracy:  86.797%\n",
      "epoch:  0  batch:  162 [  5184/7935]  loss: 0.17297384      accuracy:  86.844%\n",
      "epoch:  0  batch:  164 [  5248/7935]  loss: 0.03043112      accuracy:  86.966%\n",
      "epoch:  0  batch:  166 [  5312/7935]  loss: 0.46461719      accuracy:  86.898%\n",
      "epoch:  0  batch:  168 [  5376/7935]  loss: 0.33088776      accuracy:  86.961%\n",
      "epoch:  0  batch:  170 [  5440/7935]  loss: 0.10710829      accuracy:  87.077%\n",
      "epoch:  0  batch:  172 [  5504/7935]  loss: 0.11071114      accuracy:  87.137%\n",
      "epoch:  0  batch:  174 [  5568/7935]  loss: 0.11016315      accuracy:  87.249%\n",
      "epoch:  0  batch:  176 [  5632/7935]  loss: 0.20756161      accuracy:  87.287%\n",
      "epoch:  0  batch:  178 [  5696/7935]  loss: 0.09056914      accuracy:  87.342%\n",
      "epoch:  0  batch:  180 [  5760/7935]  loss: 0.25082785      accuracy:  87.413%\n",
      "epoch:  0  batch:  182 [  5824/7935]  loss: 0.15782362      accuracy:  87.500%\n",
      "epoch:  0  batch:  184 [  5888/7935]  loss: 0.17527355      accuracy:  87.568%\n",
      "epoch:  0  batch:  186 [  5952/7935]  loss: 0.06162252      accuracy:  87.668%\n",
      "epoch:  0  batch:  188 [  6016/7935]  loss: 0.09018262      accuracy:  87.733%\n",
      "epoch:  0  batch:  190 [  6080/7935]  loss: 0.16787022      accuracy:  87.780%\n",
      "epoch:  0  batch:  192 [  6144/7935]  loss: 0.09538706      accuracy:  87.874%\n",
      "epoch:  0  batch:  194 [  6208/7935]  loss: 0.10449261      accuracy:  87.903%\n",
      "epoch:  0  batch:  196 [  6272/7935]  loss: 0.08048984      accuracy:  87.994%\n",
      "epoch:  0  batch:  198 [  6336/7935]  loss: 0.32252398      accuracy:  88.052%\n",
      "epoch:  0  batch:  200 [  6400/7935]  loss: 0.16623911      accuracy:  88.109%\n",
      "epoch:  0  batch:  202 [  6464/7935]  loss: 0.09253196      accuracy:  88.181%\n",
      "epoch:  0  batch:  204 [  6528/7935]  loss: 0.08719027      accuracy:  88.281%\n",
      "epoch:  0  batch:  206 [  6592/7935]  loss: 0.15969923      accuracy:  88.350%\n",
      "epoch:  0  batch:  208 [  6656/7935]  loss: 0.24584702      accuracy:  88.356%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  210 [  6720/7935]  loss: 0.09136675      accuracy:  88.423%\n",
      "epoch:  0  batch:  212 [  6784/7935]  loss: 0.12743515      accuracy:  88.429%\n",
      "epoch:  0  batch:  214 [  6848/7935]  loss: 0.35156956      accuracy:  88.449%\n",
      "epoch:  0  batch:  216 [  6912/7935]  loss: 0.14224385      accuracy:  88.498%\n",
      "epoch:  0  batch:  218 [  6976/7935]  loss: 0.17087097      accuracy:  88.546%\n",
      "epoch:  0  batch:  220 [  7040/7935]  loss: 0.08011989      accuracy:  88.580%\n",
      "epoch:  0  batch:  222 [  7104/7935]  loss: 0.10732499      accuracy:  88.654%\n",
      "epoch:  0  batch:  224 [  7168/7935]  loss: 0.20263091      accuracy:  88.700%\n",
      "epoch:  0  batch:  226 [  7232/7935]  loss: 0.12777324      accuracy:  88.744%\n",
      "epoch:  0  batch:  228 [  7296/7935]  loss: 0.10327087      accuracy:  88.802%\n",
      "epoch:  0  batch:  230 [  7360/7935]  loss: 0.25482112      accuracy:  88.832%\n",
      "epoch:  0  batch:  232 [  7424/7935]  loss: 0.20956500      accuracy:  88.874%\n",
      "epoch:  0  batch:  234 [  7488/7935]  loss: 0.15306681      accuracy:  88.902%\n",
      "epoch:  0  batch:  236 [  7552/7935]  loss: 0.09409325      accuracy:  88.930%\n",
      "epoch:  0  batch:  238 [  7616/7935]  loss: 0.12246969      accuracy:  88.984%\n",
      "epoch:  0  batch:  240 [  7680/7935]  loss: 0.11743580      accuracy:  89.036%\n",
      "epoch:  0  batch:  242 [  7744/7935]  loss: 0.11618169      accuracy:  89.101%\n",
      "epoch:  0  batch:  244 [  7808/7935]  loss: 0.12798294      accuracy:  89.165%\n",
      "epoch:  0  batch:  246 [  7872/7935]  loss: 0.13269939      accuracy:  89.240%\n",
      "epoch:  0  batch:  248 [  7935/7935]  loss: 0.22206113      accuracy:  89.250%\n",
      "============= New Epoch =========================\n",
      "epoch:  1  batch:    2 [    64/7935]  loss: 0.14319028      accuracy:  93.750%\n",
      "epoch:  1  batch:    4 [   128/7935]  loss: 0.04836454      accuracy:  95.312%\n",
      "epoch:  1  batch:    6 [   192/7935]  loss: 0.07816613      accuracy:  96.875%\n",
      "epoch:  1  batch:    8 [   256/7935]  loss: 0.00879298      accuracy:  97.266%\n",
      "epoch:  1  batch:   10 [   320/7935]  loss: 0.14015940      accuracy:  96.875%\n",
      "epoch:  1  batch:   12 [   384/7935]  loss: 0.16671388      accuracy:  96.094%\n",
      "epoch:  1  batch:   14 [   448/7935]  loss: 0.26392680      accuracy:  95.089%\n",
      "epoch:  1  batch:   16 [   512/7935]  loss: 0.13695970      accuracy:  94.531%\n",
      "epoch:  1  batch:   18 [   576/7935]  loss: 0.04036359      accuracy:  94.965%\n",
      "epoch:  1  batch:   20 [   640/7935]  loss: 0.12411749      accuracy:  95.000%\n",
      "epoch:  1  batch:   22 [   704/7935]  loss: 0.14770691      accuracy:  94.744%\n",
      "epoch:  1  batch:   24 [   768/7935]  loss: 0.22642978      accuracy:  94.401%\n",
      "epoch:  1  batch:   26 [   832/7935]  loss: 0.11808880      accuracy:  94.471%\n",
      "epoch:  1  batch:   28 [   896/7935]  loss: 0.07786616      accuracy:  94.754%\n",
      "epoch:  1  batch:   30 [   960/7935]  loss: 0.07555205      accuracy:  94.688%\n",
      "epoch:  1  batch:   32 [  1024/7935]  loss: 0.07128938      accuracy:  94.629%\n",
      "epoch:  1  batch:   34 [  1088/7935]  loss: 0.21651350      accuracy:  94.210%\n",
      "epoch:  1  batch:   36 [  1152/7935]  loss: 0.05721174      accuracy:  94.010%\n",
      "epoch:  1  batch:   38 [  1216/7935]  loss: 0.11141245      accuracy:  93.832%\n",
      "epoch:  1  batch:   40 [  1280/7935]  loss: 0.22240447      accuracy:  93.359%\n",
      "epoch:  1  batch:   42 [  1344/7935]  loss: 0.07840803      accuracy:  93.601%\n",
      "epoch:  1  batch:   44 [  1408/7935]  loss: 0.09822290      accuracy:  93.608%\n",
      "epoch:  1  batch:   46 [  1472/7935]  loss: 0.18595174      accuracy:  93.614%\n",
      "epoch:  1  batch:   48 [  1536/7935]  loss: 0.28600502      accuracy:  93.490%\n",
      "epoch:  1  batch:   50 [  1600/7935]  loss: 0.18107182      accuracy:  93.562%\n",
      "epoch:  1  batch:   52 [  1664/7935]  loss: 0.28015670      accuracy:  93.630%\n",
      "epoch:  1  batch:   54 [  1728/7935]  loss: 0.11998700      accuracy:  93.519%\n",
      "epoch:  1  batch:   56 [  1792/7935]  loss: 0.12483457      accuracy:  93.527%\n",
      "epoch:  1  batch:   58 [  1856/7935]  loss: 0.08860479      accuracy:  93.534%\n",
      "epoch:  1  batch:   60 [  1920/7935]  loss: 0.16718523      accuracy:  93.594%\n",
      "epoch:  1  batch:   62 [  1984/7935]  loss: 0.04190601      accuracy:  93.750%\n",
      "epoch:  1  batch:   64 [  2048/7935]  loss: 0.06957319      accuracy:  93.799%\n",
      "epoch:  1  batch:   66 [  2112/7935]  loss: 0.16967086      accuracy:  93.845%\n",
      "epoch:  1  batch:   68 [  2176/7935]  loss: 0.08846539      accuracy:  93.842%\n",
      "epoch:  1  batch:   70 [  2240/7935]  loss: 0.04207236      accuracy:  93.929%\n",
      "epoch:  1  batch:   72 [  2304/7935]  loss: 0.14062662      accuracy:  93.924%\n",
      "epoch:  1  batch:   74 [  2368/7935]  loss: 0.08350432      accuracy:  93.961%\n",
      "epoch:  1  batch:   76 [  2432/7935]  loss: 0.12886719      accuracy:  94.038%\n",
      "epoch:  1  batch:   78 [  2496/7935]  loss: 0.07267407      accuracy:  94.030%\n",
      "epoch:  1  batch:   80 [  2560/7935]  loss: 0.27267528      accuracy:  93.945%\n",
      "epoch:  1  batch:   82 [  2624/7935]  loss: 0.12482215      accuracy:  93.902%\n",
      "epoch:  1  batch:   84 [  2688/7935]  loss: 0.08997487      accuracy:  94.010%\n",
      "epoch:  1  batch:   86 [  2752/7935]  loss: 0.11590855      accuracy:  93.968%\n",
      "epoch:  1  batch:   88 [  2816/7935]  loss: 0.04763602      accuracy:  94.034%\n",
      "epoch:  1  batch:   90 [  2880/7935]  loss: 0.10884506      accuracy:  94.132%\n",
      "epoch:  1  batch:   92 [  2944/7935]  loss: 0.31421605      accuracy:  94.056%\n",
      "epoch:  1  batch:   94 [  3008/7935]  loss: 0.14544117      accuracy:  94.082%\n",
      "epoch:  1  batch:   96 [  3072/7935]  loss: 0.10566011      accuracy:  94.108%\n",
      "epoch:  1  batch:   98 [  3136/7935]  loss: 0.09349109      accuracy:  94.165%\n",
      "epoch:  1  batch:  100 [  3200/7935]  loss: 0.09141832      accuracy:  94.219%\n",
      "epoch:  1  batch:  102 [  3264/7935]  loss: 0.15205130      accuracy:  94.210%\n",
      "epoch:  1  batch:  104 [  3328/7935]  loss: 0.11144154      accuracy:  94.171%\n",
      "epoch:  1  batch:  106 [  3392/7935]  loss: 0.06513187      accuracy:  94.222%\n",
      "epoch:  1  batch:  108 [  3456/7935]  loss: 0.07628265      accuracy:  94.097%\n",
      "epoch:  1  batch:  110 [  3520/7935]  loss: 0.13550206      accuracy:  94.148%\n",
      "epoch:  1  batch:  112 [  3584/7935]  loss: 0.04368981      accuracy:  94.196%\n",
      "epoch:  1  batch:  114 [  3648/7935]  loss: 0.07737833      accuracy:  94.243%\n",
      "epoch:  1  batch:  116 [  3712/7935]  loss: 0.05169784      accuracy:  94.262%\n",
      "epoch:  1  batch:  118 [  3776/7935]  loss: 0.02550659      accuracy:  94.333%\n",
      "epoch:  1  batch:  120 [  3840/7935]  loss: 0.04483483      accuracy:  94.401%\n",
      "epoch:  1  batch:  122 [  3904/7935]  loss: 0.09223857      accuracy:  94.442%\n",
      "epoch:  1  batch:  124 [  3968/7935]  loss: 0.01367008      accuracy:  94.506%\n",
      "epoch:  1  batch:  126 [  4032/7935]  loss: 0.15271939      accuracy:  94.494%\n",
      "epoch:  1  batch:  128 [  4096/7935]  loss: 0.04432549      accuracy:  94.556%\n",
      "epoch:  1  batch:  130 [  4160/7935]  loss: 0.03190909      accuracy:  94.615%\n",
      "epoch:  1  batch:  132 [  4224/7935]  loss: 0.11465210      accuracy:  94.650%\n",
      "epoch:  1  batch:  134 [  4288/7935]  loss: 0.19185130      accuracy:  94.706%\n",
      "epoch:  1  batch:  136 [  4352/7935]  loss: 0.03449338      accuracy:  94.692%\n",
      "epoch:  1  batch:  138 [  4416/7935]  loss: 0.14629018      accuracy:  94.746%\n",
      "epoch:  1  batch:  140 [  4480/7935]  loss: 0.11719344      accuracy:  94.777%\n",
      "epoch:  1  batch:  142 [  4544/7935]  loss: 0.04621683      accuracy:  94.806%\n",
      "epoch:  1  batch:  144 [  4608/7935]  loss: 0.01865885      accuracy:  94.857%\n",
      "epoch:  1  batch:  146 [  4672/7935]  loss: 0.11838812      accuracy:  94.863%\n",
      "epoch:  1  batch:  148 [  4736/7935]  loss: 0.29263893      accuracy:  94.869%\n",
      "epoch:  1  batch:  150 [  4800/7935]  loss: 0.04913986      accuracy:  94.875%\n",
      "epoch:  1  batch:  152 [  4864/7935]  loss: 0.37270260      accuracy:  94.799%\n",
      "epoch:  1  batch:  154 [  4928/7935]  loss: 0.06420795      accuracy:  94.765%\n",
      "epoch:  1  batch:  156 [  4992/7935]  loss: 0.41294494      accuracy:  94.631%\n",
      "epoch:  1  batch:  158 [  5056/7935]  loss: 0.05795107      accuracy:  94.620%\n",
      "epoch:  1  batch:  160 [  5120/7935]  loss: 0.09952924      accuracy:  94.629%\n",
      "epoch:  1  batch:  162 [  5184/7935]  loss: 0.15939005      accuracy:  94.599%\n",
      "epoch:  1  batch:  164 [  5248/7935]  loss: 0.09719850      accuracy:  94.646%\n",
      "epoch:  1  batch:  166 [  5312/7935]  loss: 0.02644972      accuracy:  94.691%\n",
      "epoch:  1  batch:  168 [  5376/7935]  loss: 0.25229639      accuracy:  94.624%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch:  170 [  5440/7935]  loss: 0.13426283      accuracy:  94.651%\n",
      "epoch:  1  batch:  172 [  5504/7935]  loss: 0.17274736      accuracy:  94.658%\n",
      "epoch:  1  batch:  174 [  5568/7935]  loss: 0.09876287      accuracy:  94.684%\n",
      "epoch:  1  batch:  176 [  5632/7935]  loss: 0.13725565      accuracy:  94.673%\n",
      "epoch:  1  batch:  178 [  5696/7935]  loss: 0.12484824      accuracy:  94.698%\n",
      "epoch:  1  batch:  180 [  5760/7935]  loss: 0.15520215      accuracy:  94.705%\n",
      "epoch:  1  batch:  182 [  5824/7935]  loss: 0.09977679      accuracy:  94.660%\n",
      "epoch:  1  batch:  184 [  5888/7935]  loss: 0.23620954      accuracy:  94.616%\n",
      "epoch:  1  batch:  186 [  5952/7935]  loss: 0.06272634      accuracy:  94.624%\n",
      "epoch:  1  batch:  188 [  6016/7935]  loss: 0.05017015      accuracy:  94.648%\n",
      "epoch:  1  batch:  190 [  6080/7935]  loss: 0.08021207      accuracy:  94.622%\n",
      "epoch:  1  batch:  192 [  6144/7935]  loss: 0.06926707      accuracy:  94.661%\n",
      "epoch:  1  batch:  194 [  6208/7935]  loss: 0.18246923      accuracy:  94.620%\n",
      "epoch:  1  batch:  196 [  6272/7935]  loss: 0.03669044      accuracy:  94.675%\n",
      "epoch:  1  batch:  198 [  6336/7935]  loss: 0.07652427      accuracy:  94.665%\n",
      "epoch:  1  batch:  200 [  6400/7935]  loss: 0.08960629      accuracy:  94.688%\n",
      "epoch:  1  batch:  202 [  6464/7935]  loss: 0.04065731      accuracy:  94.725%\n",
      "epoch:  1  batch:  204 [  6528/7935]  loss: 0.05707964      accuracy:  94.761%\n",
      "epoch:  1  batch:  206 [  6592/7935]  loss: 0.06187046      accuracy:  94.797%\n",
      "epoch:  1  batch:  208 [  6656/7935]  loss: 0.04396646      accuracy:  94.817%\n",
      "epoch:  1  batch:  210 [  6720/7935]  loss: 0.19662008      accuracy:  94.821%\n",
      "epoch:  1  batch:  212 [  6784/7935]  loss: 0.14161347      accuracy:  94.826%\n",
      "epoch:  1  batch:  214 [  6848/7935]  loss: 0.14879732      accuracy:  94.845%\n",
      "epoch:  1  batch:  216 [  6912/7935]  loss: 0.13561316      accuracy:  94.864%\n",
      "epoch:  1  batch:  218 [  6976/7935]  loss: 0.08432422      accuracy:  94.854%\n",
      "epoch:  1  batch:  220 [  7040/7935]  loss: 0.31972864      accuracy:  94.815%\n",
      "epoch:  1  batch:  222 [  7104/7935]  loss: 0.34457836      accuracy:  94.792%\n",
      "epoch:  1  batch:  224 [  7168/7935]  loss: 0.02890766      accuracy:  94.810%\n",
      "epoch:  1  batch:  226 [  7232/7935]  loss: 0.20857924      accuracy:  94.787%\n",
      "epoch:  1  batch:  228 [  7296/7935]  loss: 0.05493274      accuracy:  94.764%\n",
      "epoch:  1  batch:  230 [  7360/7935]  loss: 0.11303361      accuracy:  94.755%\n",
      "epoch:  1  batch:  232 [  7424/7935]  loss: 0.10742851      accuracy:  94.774%\n",
      "epoch:  1  batch:  234 [  7488/7935]  loss: 0.33157542      accuracy:  94.725%\n",
      "epoch:  1  batch:  236 [  7552/7935]  loss: 0.30635411      accuracy:  94.690%\n",
      "epoch:  1  batch:  238 [  7616/7935]  loss: 0.19981220      accuracy:  94.643%\n",
      "epoch:  1  batch:  240 [  7680/7935]  loss: 0.12048787      accuracy:  94.688%\n",
      "epoch:  1  batch:  242 [  7744/7935]  loss: 0.11367947      accuracy:  94.693%\n",
      "epoch:  1  batch:  244 [  7808/7935]  loss: 0.18974900      accuracy:  94.698%\n",
      "epoch:  1  batch:  246 [  7872/7935]  loss: 0.17921458      accuracy:  94.690%\n",
      "epoch:  1  batch:  248 [  7935/7935]  loss: 0.15615699      accuracy:  94.694%\n",
      "============= New Epoch =========================\n",
      "epoch:  2  batch:    2 [    64/7935]  loss: 0.13170318      accuracy:  95.312%\n",
      "epoch:  2  batch:    4 [   128/7935]  loss: 0.10526928      accuracy:  96.094%\n",
      "epoch:  2  batch:    6 [   192/7935]  loss: 0.04326743      accuracy:  97.396%\n",
      "epoch:  2  batch:    8 [   256/7935]  loss: 0.12652743      accuracy:  96.094%\n",
      "epoch:  2  batch:   10 [   320/7935]  loss: 0.09577623      accuracy:  95.000%\n",
      "epoch:  2  batch:   12 [   384/7935]  loss: 0.11495367      accuracy:  95.573%\n",
      "epoch:  2  batch:   14 [   448/7935]  loss: 0.08118766      accuracy:  95.312%\n",
      "epoch:  2  batch:   16 [   512/7935]  loss: 0.15431114      accuracy:  95.703%\n",
      "epoch:  2  batch:   18 [   576/7935]  loss: 0.01962493      accuracy:  96.181%\n",
      "epoch:  2  batch:   20 [   640/7935]  loss: 0.09047010      accuracy:  95.938%\n",
      "epoch:  2  batch:   22 [   704/7935]  loss: 0.03900827      accuracy:  96.165%\n",
      "epoch:  2  batch:   24 [   768/7935]  loss: 0.11069503      accuracy:  96.094%\n",
      "epoch:  2  batch:   26 [   832/7935]  loss: 0.09485326      accuracy:  96.034%\n",
      "epoch:  2  batch:   28 [   896/7935]  loss: 0.14875256      accuracy:  95.759%\n",
      "epoch:  2  batch:   30 [   960/7935]  loss: 0.20820743      accuracy:  95.521%\n",
      "epoch:  2  batch:   32 [  1024/7935]  loss: 0.17370415      accuracy:  95.605%\n",
      "epoch:  2  batch:   34 [  1088/7935]  loss: 0.21080738      accuracy:  95.680%\n",
      "epoch:  2  batch:   36 [  1152/7935]  loss: 0.06029611      accuracy:  95.747%\n",
      "epoch:  2  batch:   38 [  1216/7935]  loss: 0.08806364      accuracy:  95.641%\n",
      "epoch:  2  batch:   40 [  1280/7935]  loss: 0.05966485      accuracy:  95.703%\n",
      "epoch:  2  batch:   42 [  1344/7935]  loss: 0.12564521      accuracy:  95.685%\n",
      "epoch:  2  batch:   44 [  1408/7935]  loss: 0.05951752      accuracy:  95.810%\n",
      "epoch:  2  batch:   46 [  1472/7935]  loss: 0.06528066      accuracy:  95.856%\n",
      "epoch:  2  batch:   48 [  1536/7935]  loss: 0.03409487      accuracy:  96.029%\n",
      "epoch:  2  batch:   50 [  1600/7935]  loss: 0.06745527      accuracy:  96.062%\n",
      "epoch:  2  batch:   52 [  1664/7935]  loss: 0.04615790      accuracy:  96.154%\n",
      "epoch:  2  batch:   54 [  1728/7935]  loss: 0.06357197      accuracy:  96.181%\n",
      "epoch:  2  batch:   56 [  1792/7935]  loss: 0.05262378      accuracy:  96.205%\n",
      "epoch:  2  batch:   58 [  1856/7935]  loss: 0.00382582      accuracy:  96.282%\n",
      "epoch:  2  batch:   60 [  1920/7935]  loss: 0.04627889      accuracy:  96.354%\n",
      "epoch:  2  batch:   62 [  1984/7935]  loss: 0.20769069      accuracy:  96.220%\n",
      "epoch:  2  batch:   64 [  2048/7935]  loss: 0.02062393      accuracy:  96.289%\n",
      "epoch:  2  batch:   66 [  2112/7935]  loss: 0.08399966      accuracy:  96.354%\n",
      "epoch:  2  batch:   68 [  2176/7935]  loss: 0.02448677      accuracy:  96.369%\n",
      "epoch:  2  batch:   70 [  2240/7935]  loss: 0.00931193      accuracy:  96.384%\n",
      "epoch:  2  batch:   72 [  2304/7935]  loss: 0.01596286      accuracy:  96.484%\n",
      "epoch:  2  batch:   74 [  2368/7935]  loss: 0.03107544      accuracy:  96.537%\n",
      "epoch:  2  batch:   76 [  2432/7935]  loss: 0.03342126      accuracy:  96.546%\n",
      "epoch:  2  batch:   78 [  2496/7935]  loss: 0.03160182      accuracy:  96.554%\n",
      "epoch:  2  batch:   80 [  2560/7935]  loss: 0.19587663      accuracy:  96.602%\n",
      "epoch:  2  batch:   82 [  2624/7935]  loss: 0.04181151      accuracy:  96.608%\n",
      "epoch:  2  batch:   84 [  2688/7935]  loss: 0.03969640      accuracy:  96.652%\n",
      "epoch:  2  batch:   86 [  2752/7935]  loss: 0.10625193      accuracy:  96.584%\n",
      "epoch:  2  batch:   88 [  2816/7935]  loss: 0.08981045      accuracy:  96.591%\n",
      "epoch:  2  batch:   90 [  2880/7935]  loss: 0.10104938      accuracy:  96.597%\n",
      "epoch:  2  batch:   92 [  2944/7935]  loss: 0.04312011      accuracy:  96.637%\n",
      "epoch:  2  batch:   94 [  3008/7935]  loss: 0.02073218      accuracy:  96.676%\n",
      "epoch:  2  batch:   96 [  3072/7935]  loss: 0.03283367      accuracy:  96.680%\n",
      "epoch:  2  batch:   98 [  3136/7935]  loss: 0.10321112      accuracy:  96.588%\n",
      "epoch:  2  batch:  100 [  3200/7935]  loss: 0.01868594      accuracy:  96.656%\n",
      "epoch:  2  batch:  102 [  3264/7935]  loss: 0.03183280      accuracy:  96.691%\n",
      "epoch:  2  batch:  104 [  3328/7935]  loss: 0.02171933      accuracy:  96.725%\n",
      "epoch:  2  batch:  106 [  3392/7935]  loss: 0.10545867      accuracy:  96.669%\n",
      "epoch:  2  batch:  108 [  3456/7935]  loss: 0.07237487      accuracy:  96.701%\n",
      "epoch:  2  batch:  110 [  3520/7935]  loss: 0.04245109      accuracy:  96.761%\n",
      "epoch:  2  batch:  112 [  3584/7935]  loss: 0.03781280      accuracy:  96.791%\n",
      "epoch:  2  batch:  114 [  3648/7935]  loss: 0.03153596      accuracy:  96.793%\n",
      "epoch:  2  batch:  116 [  3712/7935]  loss: 0.14197582      accuracy:  96.794%\n",
      "epoch:  2  batch:  118 [  3776/7935]  loss: 0.02851051      accuracy:  96.822%\n",
      "epoch:  2  batch:  120 [  3840/7935]  loss: 0.00158405      accuracy:  96.797%\n",
      "epoch:  2  batch:  122 [  3904/7935]  loss: 0.12335605      accuracy:  96.773%\n",
      "epoch:  2  batch:  124 [  3968/7935]  loss: 0.02492337      accuracy:  96.774%\n",
      "epoch:  2  batch:  126 [  4032/7935]  loss: 0.02037650      accuracy:  96.825%\n",
      "epoch:  2  batch:  128 [  4096/7935]  loss: 0.04894776      accuracy:  96.851%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2  batch:  130 [  4160/7935]  loss: 0.00922396      accuracy:  96.875%\n",
      "epoch:  2  batch:  132 [  4224/7935]  loss: 0.14723459      accuracy:  96.875%\n",
      "epoch:  2  batch:  134 [  4288/7935]  loss: 0.03291573      accuracy:  96.898%\n",
      "epoch:  2  batch:  136 [  4352/7935]  loss: 0.02164396      accuracy:  96.944%\n",
      "epoch:  2  batch:  138 [  4416/7935]  loss: 0.13316241      accuracy:  96.966%\n",
      "epoch:  2  batch:  140 [  4480/7935]  loss: 0.04234303      accuracy:  96.964%\n",
      "epoch:  2  batch:  142 [  4544/7935]  loss: 0.05352684      accuracy:  96.963%\n",
      "epoch:  2  batch:  144 [  4608/7935]  loss: 0.07069451      accuracy:  96.984%\n",
      "epoch:  2  batch:  146 [  4672/7935]  loss: 0.02240704      accuracy:  97.025%\n",
      "epoch:  2  batch:  148 [  4736/7935]  loss: 0.25664470      accuracy:  96.981%\n",
      "epoch:  2  batch:  150 [  4800/7935]  loss: 0.01201317      accuracy:  97.021%\n",
      "epoch:  2  batch:  152 [  4864/7935]  loss: 0.02788808      accuracy:  97.039%\n",
      "epoch:  2  batch:  154 [  4928/7935]  loss: 0.06491970      accuracy:  97.037%\n",
      "epoch:  2  batch:  156 [  4992/7935]  loss: 0.01822858      accuracy:  97.055%\n",
      "epoch:  2  batch:  158 [  5056/7935]  loss: 0.02468771      accuracy:  97.093%\n",
      "epoch:  2  batch:  160 [  5120/7935]  loss: 0.06875568      accuracy:  97.090%\n",
      "epoch:  2  batch:  162 [  5184/7935]  loss: 0.04629618      accuracy:  97.106%\n",
      "epoch:  2  batch:  164 [  5248/7935]  loss: 0.03629429      accuracy:  97.104%\n",
      "epoch:  2  batch:  166 [  5312/7935]  loss: 0.01461140      accuracy:  97.139%\n",
      "epoch:  2  batch:  168 [  5376/7935]  loss: 0.04653795      accuracy:  97.154%\n",
      "epoch:  2  batch:  170 [  5440/7935]  loss: 0.01759502      accuracy:  97.169%\n",
      "epoch:  2  batch:  172 [  5504/7935]  loss: 0.11421208      accuracy:  97.166%\n",
      "epoch:  2  batch:  174 [  5568/7935]  loss: 0.04729160      accuracy:  97.162%\n",
      "epoch:  2  batch:  176 [  5632/7935]  loss: 0.11443001      accuracy:  97.124%\n",
      "epoch:  2  batch:  178 [  5696/7935]  loss: 0.02087032      accuracy:  97.121%\n",
      "epoch:  2  batch:  180 [  5760/7935]  loss: 0.07278939      accuracy:  97.118%\n",
      "epoch:  2  batch:  182 [  5824/7935]  loss: 0.04650716      accuracy:  97.115%\n",
      "epoch:  2  batch:  184 [  5888/7935]  loss: 0.00959632      accuracy:  97.130%\n",
      "epoch:  2  batch:  186 [  5952/7935]  loss: 0.03785603      accuracy:  97.127%\n",
      "epoch:  2  batch:  188 [  6016/7935]  loss: 0.02133235      accuracy:  97.141%\n",
      "epoch:  2  batch:  190 [  6080/7935]  loss: 0.10031962      accuracy:  97.138%\n",
      "epoch:  2  batch:  192 [  6144/7935]  loss: 0.01715405      accuracy:  97.168%\n",
      "epoch:  2  batch:  194 [  6208/7935]  loss: 0.02347875      accuracy:  97.165%\n",
      "epoch:  2  batch:  196 [  6272/7935]  loss: 0.11003473      accuracy:  97.162%\n",
      "epoch:  2  batch:  198 [  6336/7935]  loss: 0.01929460      accuracy:  97.175%\n",
      "epoch:  2  batch:  200 [  6400/7935]  loss: 0.02584606      accuracy:  97.188%\n",
      "epoch:  2  batch:  202 [  6464/7935]  loss: 0.01226303      accuracy:  97.215%\n",
      "epoch:  2  batch:  204 [  6528/7935]  loss: 0.00742573      accuracy:  97.243%\n",
      "epoch:  2  batch:  206 [  6592/7935]  loss: 0.04041651      accuracy:  97.254%\n",
      "epoch:  2  batch:  208 [  6656/7935]  loss: 0.03178720      accuracy:  97.266%\n",
      "epoch:  2  batch:  210 [  6720/7935]  loss: 0.03881318      accuracy:  97.262%\n",
      "epoch:  2  batch:  212 [  6784/7935]  loss: 0.00199368      accuracy:  97.288%\n",
      "epoch:  2  batch:  214 [  6848/7935]  loss: 0.02472775      accuracy:  97.313%\n",
      "epoch:  2  batch:  216 [  6912/7935]  loss: 0.02802519      accuracy:  97.323%\n",
      "epoch:  2  batch:  218 [  6976/7935]  loss: 0.00779200      accuracy:  97.348%\n",
      "epoch:  2  batch:  220 [  7040/7935]  loss: 0.02516982      accuracy:  97.372%\n",
      "epoch:  2  batch:  222 [  7104/7935]  loss: 0.10556263      accuracy:  97.368%\n",
      "epoch:  2  batch:  224 [  7168/7935]  loss: 0.01033863      accuracy:  97.391%\n",
      "epoch:  2  batch:  226 [  7232/7935]  loss: 0.09842524      accuracy:  97.387%\n",
      "epoch:  2  batch:  228 [  7296/7935]  loss: 0.01760748      accuracy:  97.410%\n",
      "epoch:  2  batch:  230 [  7360/7935]  loss: 0.01234124      accuracy:  97.432%\n",
      "epoch:  2  batch:  232 [  7424/7935]  loss: 0.02245550      accuracy:  97.454%\n",
      "epoch:  2  batch:  234 [  7488/7935]  loss: 0.08555792      accuracy:  97.449%\n",
      "epoch:  2  batch:  236 [  7552/7935]  loss: 0.03905189      accuracy:  97.458%\n",
      "epoch:  2  batch:  238 [  7616/7935]  loss: 0.08291353      accuracy:  97.440%\n",
      "epoch:  2  batch:  240 [  7680/7935]  loss: 0.00836945      accuracy:  97.461%\n",
      "epoch:  2  batch:  242 [  7744/7935]  loss: 0.03466412      accuracy:  97.469%\n",
      "epoch:  2  batch:  244 [  7808/7935]  loss: 0.02641449      accuracy:  97.490%\n",
      "epoch:  2  batch:  246 [  7872/7935]  loss: 0.00225339      accuracy:  97.510%\n",
      "epoch:  2  batch:  248 [  7935/7935]  loss: 0.00858256      accuracy:  97.530%\n",
      "============= New Epoch =========================\n",
      "epoch:  3  batch:    2 [    64/7935]  loss: 0.03521905      accuracy:  98.438%\n",
      "epoch:  3  batch:    4 [   128/7935]  loss: 0.01439349      accuracy:  99.219%\n",
      "epoch:  3  batch:    6 [   192/7935]  loss: 0.03186846      accuracy:  99.479%\n",
      "epoch:  3  batch:    8 [   256/7935]  loss: 0.01325521      accuracy:  99.609%\n",
      "epoch:  3  batch:   10 [   320/7935]  loss: 0.00679505      accuracy:  99.688%\n",
      "epoch:  3  batch:   12 [   384/7935]  loss: 0.03551300      accuracy:  99.219%\n",
      "epoch:  3  batch:   14 [   448/7935]  loss: 0.00124625      accuracy:  99.330%\n",
      "epoch:  3  batch:   16 [   512/7935]  loss: 0.00142742      accuracy:  99.414%\n",
      "epoch:  3  batch:   18 [   576/7935]  loss: 0.00220469      accuracy:  99.479%\n",
      "epoch:  3  batch:   20 [   640/7935]  loss: 0.00187388      accuracy:  99.531%\n",
      "epoch:  3  batch:   22 [   704/7935]  loss: 0.00197051      accuracy:  99.574%\n",
      "epoch:  3  batch:   24 [   768/7935]  loss: 0.02787588      accuracy:  99.609%\n",
      "epoch:  3  batch:   26 [   832/7935]  loss: 0.00576154      accuracy:  99.639%\n",
      "epoch:  3  batch:   28 [   896/7935]  loss: 0.03095485      accuracy:  99.665%\n",
      "epoch:  3  batch:   30 [   960/7935]  loss: 0.00382440      accuracy:  99.688%\n",
      "epoch:  3  batch:   32 [  1024/7935]  loss: 0.01283732      accuracy:  99.707%\n",
      "epoch:  3  batch:   34 [  1088/7935]  loss: 0.01858244      accuracy:  99.724%\n",
      "epoch:  3  batch:   36 [  1152/7935]  loss: 0.00617731      accuracy:  99.740%\n",
      "epoch:  3  batch:   38 [  1216/7935]  loss: 0.00325846      accuracy:  99.753%\n",
      "epoch:  3  batch:   40 [  1280/7935]  loss: 0.02265255      accuracy:  99.688%\n",
      "epoch:  3  batch:   42 [  1344/7935]  loss: 0.00619612      accuracy:  99.702%\n",
      "epoch:  3  batch:   44 [  1408/7935]  loss: 0.02161965      accuracy:  99.716%\n",
      "epoch:  3  batch:   46 [  1472/7935]  loss: 0.01266311      accuracy:  99.728%\n",
      "epoch:  3  batch:   48 [  1536/7935]  loss: 0.00159798      accuracy:  99.740%\n",
      "epoch:  3  batch:   50 [  1600/7935]  loss: 0.00116962      accuracy:  99.688%\n",
      "epoch:  3  batch:   52 [  1664/7935]  loss: 0.00281745      accuracy:  99.700%\n",
      "epoch:  3  batch:   54 [  1728/7935]  loss: 0.00453286      accuracy:  99.711%\n",
      "epoch:  3  batch:   56 [  1792/7935]  loss: 0.00062831      accuracy:  99.721%\n",
      "epoch:  3  batch:   58 [  1856/7935]  loss: 0.00046250      accuracy:  99.731%\n",
      "epoch:  3  batch:   60 [  1920/7935]  loss: 0.04878064      accuracy:  99.688%\n",
      "epoch:  3  batch:   62 [  1984/7935]  loss: 0.10697522      accuracy:  99.647%\n",
      "epoch:  3  batch:   64 [  2048/7935]  loss: 0.00111339      accuracy:  99.658%\n",
      "epoch:  3  batch:   66 [  2112/7935]  loss: 0.05418956      accuracy:  99.574%\n",
      "epoch:  3  batch:   68 [  2176/7935]  loss: 0.00338235      accuracy:  99.540%\n",
      "epoch:  3  batch:   70 [  2240/7935]  loss: 0.09775534      accuracy:  99.420%\n",
      "epoch:  3  batch:   72 [  2304/7935]  loss: 0.01191744      accuracy:  99.436%\n",
      "epoch:  3  batch:   74 [  2368/7935]  loss: 0.01420133      accuracy:  99.451%\n",
      "epoch:  3  batch:   76 [  2432/7935]  loss: 0.02021667      accuracy:  99.465%\n",
      "epoch:  3  batch:   78 [  2496/7935]  loss: 0.00456223      accuracy:  99.399%\n",
      "epoch:  3  batch:   80 [  2560/7935]  loss: 0.00907874      accuracy:  99.414%\n",
      "epoch:  3  batch:   82 [  2624/7935]  loss: 0.02466066      accuracy:  99.390%\n",
      "epoch:  3  batch:   84 [  2688/7935]  loss: 0.00736824      accuracy:  99.405%\n",
      "epoch:  3  batch:   86 [  2752/7935]  loss: 0.00853061      accuracy:  99.419%\n",
      "epoch:  3  batch:   88 [  2816/7935]  loss: 0.06444669      accuracy:  99.396%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3  batch:   90 [  2880/7935]  loss: 0.00407490      accuracy:  99.410%\n",
      "epoch:  3  batch:   92 [  2944/7935]  loss: 0.04676343      accuracy:  99.389%\n",
      "epoch:  3  batch:   94 [  3008/7935]  loss: 0.02728568      accuracy:  99.402%\n",
      "epoch:  3  batch:   96 [  3072/7935]  loss: 0.01949855      accuracy:  99.414%\n",
      "epoch:  3  batch:   98 [  3136/7935]  loss: 0.01402369      accuracy:  99.394%\n",
      "epoch:  3  batch:  100 [  3200/7935]  loss: 0.00194332      accuracy:  99.406%\n",
      "epoch:  3  batch:  102 [  3264/7935]  loss: 0.10713653      accuracy:  99.387%\n",
      "epoch:  3  batch:  104 [  3328/7935]  loss: 0.04930139      accuracy:  99.309%\n",
      "epoch:  3  batch:  106 [  3392/7935]  loss: 0.02804268      accuracy:  99.263%\n",
      "epoch:  3  batch:  108 [  3456/7935]  loss: 0.30329213      accuracy:  99.161%\n",
      "epoch:  3  batch:  110 [  3520/7935]  loss: 0.02634988      accuracy:  99.176%\n",
      "epoch:  3  batch:  112 [  3584/7935]  loss: 0.15369414      accuracy:  99.107%\n",
      "epoch:  3  batch:  114 [  3648/7935]  loss: 0.01638645      accuracy:  99.041%\n",
      "epoch:  3  batch:  116 [  3712/7935]  loss: 0.00202479      accuracy:  99.057%\n",
      "epoch:  3  batch:  118 [  3776/7935]  loss: 0.46498230      accuracy:  98.782%\n",
      "epoch:  3  batch:  120 [  3840/7935]  loss: 0.05507792      accuracy:  98.750%\n",
      "epoch:  3  batch:  122 [  3904/7935]  loss: 0.11389307      accuracy:  98.642%\n",
      "epoch:  3  batch:  124 [  3968/7935]  loss: 0.14074868      accuracy:  98.513%\n",
      "epoch:  3  batch:  126 [  4032/7935]  loss: 0.05893501      accuracy:  98.487%\n",
      "epoch:  3  batch:  128 [  4096/7935]  loss: 0.02421369      accuracy:  98.511%\n",
      "epoch:  3  batch:  130 [  4160/7935]  loss: 0.14031217      accuracy:  98.438%\n",
      "epoch:  3  batch:  132 [  4224/7935]  loss: 0.04110480      accuracy:  98.390%\n",
      "epoch:  3  batch:  134 [  4288/7935]  loss: 0.07276013      accuracy:  98.368%\n",
      "epoch:  3  batch:  136 [  4352/7935]  loss: 0.02287470      accuracy:  98.392%\n",
      "epoch:  3  batch:  138 [  4416/7935]  loss: 0.03138027      accuracy:  98.415%\n",
      "epoch:  3  batch:  140 [  4480/7935]  loss: 0.00398148      accuracy:  98.393%\n",
      "epoch:  3  batch:  142 [  4544/7935]  loss: 0.06634951      accuracy:  98.393%\n",
      "epoch:  3  batch:  144 [  4608/7935]  loss: 0.22105724      accuracy:  98.351%\n",
      "epoch:  3  batch:  146 [  4672/7935]  loss: 0.00459413      accuracy:  98.352%\n",
      "epoch:  3  batch:  148 [  4736/7935]  loss: 0.12296493      accuracy:  98.290%\n",
      "epoch:  3  batch:  150 [  4800/7935]  loss: 0.01400212      accuracy:  98.250%\n",
      "epoch:  3  batch:  152 [  4864/7935]  loss: 0.01246068      accuracy:  98.273%\n",
      "epoch:  3  batch:  154 [  4928/7935]  loss: 0.14578299      accuracy:  98.214%\n",
      "epoch:  3  batch:  156 [  4992/7935]  loss: 0.01433645      accuracy:  98.217%\n",
      "epoch:  3  batch:  158 [  5056/7935]  loss: 0.06878892      accuracy:  98.200%\n",
      "epoch:  3  batch:  160 [  5120/7935]  loss: 0.13178985      accuracy:  98.145%\n",
      "epoch:  3  batch:  162 [  5184/7935]  loss: 0.07592002      accuracy:  98.110%\n",
      "epoch:  3  batch:  164 [  5248/7935]  loss: 0.02906630      accuracy:  98.133%\n",
      "epoch:  3  batch:  166 [  5312/7935]  loss: 0.02885680      accuracy:  98.136%\n",
      "epoch:  3  batch:  168 [  5376/7935]  loss: 0.02158869      accuracy:  98.158%\n",
      "epoch:  3  batch:  170 [  5440/7935]  loss: 0.04554438      accuracy:  98.143%\n",
      "epoch:  3  batch:  172 [  5504/7935]  loss: 0.00924109      accuracy:  98.165%\n",
      "epoch:  3  batch:  174 [  5568/7935]  loss: 0.01592540      accuracy:  98.186%\n",
      "epoch:  3  batch:  176 [  5632/7935]  loss: 0.01853763      accuracy:  98.207%\n",
      "epoch:  3  batch:  178 [  5696/7935]  loss: 0.02452518      accuracy:  98.227%\n",
      "epoch:  3  batch:  180 [  5760/7935]  loss: 0.01624042      accuracy:  98.247%\n",
      "epoch:  3  batch:  182 [  5824/7935]  loss: 0.01080739      accuracy:  98.266%\n",
      "epoch:  3  batch:  184 [  5888/7935]  loss: 0.00435312      accuracy:  98.285%\n",
      "epoch:  3  batch:  186 [  5952/7935]  loss: 0.01838972      accuracy:  98.286%\n",
      "epoch:  3  batch:  188 [  6016/7935]  loss: 0.04366228      accuracy:  98.305%\n",
      "epoch:  3  batch:  190 [  6080/7935]  loss: 0.04062019      accuracy:  98.306%\n",
      "epoch:  3  batch:  192 [  6144/7935]  loss: 0.00051469      accuracy:  98.324%\n",
      "epoch:  3  batch:  194 [  6208/7935]  loss: 0.04908286      accuracy:  98.309%\n",
      "epoch:  3  batch:  196 [  6272/7935]  loss: 0.00299268      accuracy:  98.326%\n",
      "epoch:  3  batch:  198 [  6336/7935]  loss: 0.01879243      accuracy:  98.343%\n",
      "epoch:  3  batch:  200 [  6400/7935]  loss: 0.00284530      accuracy:  98.344%\n",
      "epoch:  3  batch:  202 [  6464/7935]  loss: 0.00288008      accuracy:  98.360%\n",
      "epoch:  3  batch:  204 [  6528/7935]  loss: 0.18293203      accuracy:  98.346%\n",
      "epoch:  3  batch:  206 [  6592/7935]  loss: 0.03012089      accuracy:  98.346%\n",
      "epoch:  3  batch:  208 [  6656/7935]  loss: 0.01228985      accuracy:  98.362%\n",
      "epoch:  3  batch:  210 [  6720/7935]  loss: 0.00651062      accuracy:  98.363%\n",
      "epoch:  3  batch:  212 [  6784/7935]  loss: 0.00166545      accuracy:  98.379%\n",
      "epoch:  3  batch:  214 [  6848/7935]  loss: 0.00124138      accuracy:  98.394%\n",
      "epoch:  3  batch:  216 [  6912/7935]  loss: 0.00229161      accuracy:  98.409%\n",
      "epoch:  3  batch:  218 [  6976/7935]  loss: 0.00145587      accuracy:  98.409%\n",
      "epoch:  3  batch:  220 [  7040/7935]  loss: 0.07466531      accuracy:  98.381%\n",
      "epoch:  3  batch:  222 [  7104/7935]  loss: 0.07829081      accuracy:  98.367%\n",
      "epoch:  3  batch:  224 [  7168/7935]  loss: 0.00980287      accuracy:  98.382%\n",
      "epoch:  3  batch:  226 [  7232/7935]  loss: 0.01998524      accuracy:  98.396%\n",
      "epoch:  3  batch:  228 [  7296/7935]  loss: 0.02788680      accuracy:  98.396%\n",
      "epoch:  3  batch:  230 [  7360/7935]  loss: 0.06561542      accuracy:  98.383%\n",
      "epoch:  3  batch:  232 [  7424/7935]  loss: 0.02635913      accuracy:  98.370%\n",
      "epoch:  3  batch:  234 [  7488/7935]  loss: 0.00237125      accuracy:  98.384%\n",
      "epoch:  3  batch:  236 [  7552/7935]  loss: 0.02526296      accuracy:  98.385%\n",
      "epoch:  3  batch:  238 [  7616/7935]  loss: 0.00052641      accuracy:  98.398%\n",
      "epoch:  3  batch:  240 [  7680/7935]  loss: 0.00088076      accuracy:  98.411%\n",
      "epoch:  3  batch:  242 [  7744/7935]  loss: 0.00830911      accuracy:  98.425%\n",
      "epoch:  3  batch:  244 [  7808/7935]  loss: 0.00023387      accuracy:  98.425%\n",
      "epoch:  3  batch:  246 [  7872/7935]  loss: 0.01258546      accuracy:  98.438%\n",
      "epoch:  3  batch:  248 [  7935/7935]  loss: 0.00084873      accuracy:  98.437%\n",
      "============= New Epoch =========================\n",
      "epoch:  4  batch:    2 [    64/7935]  loss: 0.00180364      accuracy: 100.000%\n",
      "epoch:  4  batch:    4 [   128/7935]  loss: 0.00103459      accuracy: 100.000%\n",
      "epoch:  4  batch:    6 [   192/7935]  loss: 0.00715385      accuracy: 100.000%\n",
      "epoch:  4  batch:    8 [   256/7935]  loss: 0.03631472      accuracy:  99.609%\n",
      "epoch:  4  batch:   10 [   320/7935]  loss: 0.00053752      accuracy:  99.688%\n",
      "epoch:  4  batch:   12 [   384/7935]  loss: 0.00446934      accuracy:  99.740%\n",
      "epoch:  4  batch:   14 [   448/7935]  loss: 0.02758445      accuracy:  99.777%\n",
      "epoch:  4  batch:   16 [   512/7935]  loss: 0.00268833      accuracy:  99.805%\n",
      "epoch:  4  batch:   18 [   576/7935]  loss: 0.00461153      accuracy:  99.826%\n",
      "epoch:  4  batch:   20 [   640/7935]  loss: 0.01187252      accuracy:  99.844%\n",
      "epoch:  4  batch:   22 [   704/7935]  loss: 0.00078517      accuracy:  99.858%\n",
      "epoch:  4  batch:   24 [   768/7935]  loss: 0.00083112      accuracy:  99.870%\n",
      "epoch:  4  batch:   26 [   832/7935]  loss: 0.01771932      accuracy:  99.880%\n",
      "epoch:  4  batch:   28 [   896/7935]  loss: 0.00874752      accuracy:  99.888%\n",
      "epoch:  4  batch:   30 [   960/7935]  loss: 0.06600711      accuracy:  99.792%\n",
      "epoch:  4  batch:   32 [  1024/7935]  loss: 0.00072426      accuracy:  99.805%\n",
      "epoch:  4  batch:   34 [  1088/7935]  loss: 0.00012622      accuracy:  99.816%\n",
      "epoch:  4  batch:   36 [  1152/7935]  loss: 0.00221965      accuracy:  99.826%\n",
      "epoch:  4  batch:   38 [  1216/7935]  loss: 0.01909016      accuracy:  99.836%\n",
      "epoch:  4  batch:   40 [  1280/7935]  loss: 0.00439831      accuracy:  99.844%\n",
      "epoch:  4  batch:   42 [  1344/7935]  loss: 0.01011066      accuracy:  99.851%\n",
      "epoch:  4  batch:   44 [  1408/7935]  loss: 0.02304967      accuracy:  99.787%\n",
      "epoch:  4  batch:   46 [  1472/7935]  loss: 0.00502622      accuracy:  99.796%\n",
      "epoch:  4  batch:   48 [  1536/7935]  loss: 0.00107812      accuracy:  99.805%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4  batch:   50 [  1600/7935]  loss: 0.00062220      accuracy:  99.812%\n",
      "epoch:  4  batch:   52 [  1664/7935]  loss: 0.00334013      accuracy:  99.820%\n",
      "epoch:  4  batch:   54 [  1728/7935]  loss: 0.00535335      accuracy:  99.826%\n",
      "epoch:  4  batch:   56 [  1792/7935]  loss: 0.00297549      accuracy:  99.833%\n",
      "epoch:  4  batch:   58 [  1856/7935]  loss: 0.00269622      accuracy:  99.838%\n",
      "epoch:  4  batch:   60 [  1920/7935]  loss: 0.00029695      accuracy:  99.844%\n",
      "epoch:  4  batch:   62 [  1984/7935]  loss: 0.00479631      accuracy:  99.849%\n",
      "epoch:  4  batch:   64 [  2048/7935]  loss: 0.00059675      accuracy:  99.854%\n",
      "epoch:  4  batch:   66 [  2112/7935]  loss: 0.00014805      accuracy:  99.858%\n",
      "epoch:  4  batch:   68 [  2176/7935]  loss: 0.00074926      accuracy:  99.862%\n",
      "epoch:  4  batch:   70 [  2240/7935]  loss: 0.00332059      accuracy:  99.866%\n",
      "epoch:  4  batch:   72 [  2304/7935]  loss: 0.00116521      accuracy:  99.870%\n",
      "epoch:  4  batch:   74 [  2368/7935]  loss: 0.05774952      accuracy:  99.831%\n",
      "epoch:  4  batch:   76 [  2432/7935]  loss: 0.00853714      accuracy:  99.836%\n",
      "epoch:  4  batch:   78 [  2496/7935]  loss: 0.00471705      accuracy:  99.800%\n",
      "epoch:  4  batch:   80 [  2560/7935]  loss: 0.05824642      accuracy:  99.766%\n",
      "epoch:  4  batch:   82 [  2624/7935]  loss: 0.00055511      accuracy:  99.771%\n",
      "epoch:  4  batch:   84 [  2688/7935]  loss: 0.00242553      accuracy:  99.777%\n",
      "epoch:  4  batch:   86 [  2752/7935]  loss: 0.00303311      accuracy:  99.782%\n",
      "epoch:  4  batch:   88 [  2816/7935]  loss: 0.00010024      accuracy:  99.787%\n",
      "epoch:  4  batch:   90 [  2880/7935]  loss: 0.00427283      accuracy:  99.757%\n",
      "epoch:  4  batch:   92 [  2944/7935]  loss: 0.54139328      accuracy:  99.626%\n",
      "epoch:  4  batch:   94 [  3008/7935]  loss: 0.01481468      accuracy:  99.568%\n",
      "epoch:  4  batch:   96 [  3072/7935]  loss: 0.15422218      accuracy:  99.544%\n",
      "epoch:  4  batch:   98 [  3136/7935]  loss: 0.07163110      accuracy:  99.458%\n",
      "epoch:  4  batch:  100 [  3200/7935]  loss: 0.00684039      accuracy:  99.406%\n",
      "epoch:  4  batch:  102 [  3264/7935]  loss: 0.07863510      accuracy:  99.387%\n",
      "epoch:  4  batch:  104 [  3328/7935]  loss: 0.09087086      accuracy:  99.219%\n",
      "epoch:  4  batch:  106 [  3392/7935]  loss: 0.05457470      accuracy:  99.204%\n",
      "epoch:  4  batch:  108 [  3456/7935]  loss: 0.11881277      accuracy:  99.161%\n",
      "epoch:  4  batch:  110 [  3520/7935]  loss: 0.12024267      accuracy:  99.119%\n",
      "epoch:  4  batch:  112 [  3584/7935]  loss: 0.07302727      accuracy:  99.107%\n",
      "epoch:  4  batch:  114 [  3648/7935]  loss: 0.06584330      accuracy:  99.095%\n",
      "epoch:  4  batch:  116 [  3712/7935]  loss: 0.04930990      accuracy:  99.057%\n",
      "epoch:  4  batch:  118 [  3776/7935]  loss: 0.03173503      accuracy:  98.994%\n",
      "epoch:  4  batch:  120 [  3840/7935]  loss: 0.04700205      accuracy:  98.984%\n",
      "epoch:  4  batch:  122 [  3904/7935]  loss: 0.05515039      accuracy:  98.924%\n",
      "epoch:  4  batch:  124 [  3968/7935]  loss: 0.01279174      accuracy:  98.942%\n",
      "epoch:  4  batch:  126 [  4032/7935]  loss: 0.03751385      accuracy:  98.934%\n",
      "epoch:  4  batch:  128 [  4096/7935]  loss: 0.02192743      accuracy:  98.950%\n",
      "epoch:  4  batch:  130 [  4160/7935]  loss: 0.01447788      accuracy:  98.942%\n",
      "epoch:  4  batch:  132 [  4224/7935]  loss: 0.03184080      accuracy:  98.935%\n",
      "epoch:  4  batch:  134 [  4288/7935]  loss: 0.00419271      accuracy:  98.951%\n",
      "epoch:  4  batch:  136 [  4352/7935]  loss: 0.59935850      accuracy:  98.874%\n",
      "epoch:  4  batch:  138 [  4416/7935]  loss: 0.13739219      accuracy:  98.845%\n",
      "epoch:  4  batch:  140 [  4480/7935]  loss: 0.12412436      accuracy:  98.728%\n",
      "epoch:  4  batch:  142 [  4544/7935]  loss: 0.06277941      accuracy:  98.658%\n",
      "epoch:  4  batch:  144 [  4608/7935]  loss: 0.06171784      accuracy:  98.655%\n",
      "epoch:  4  batch:  146 [  4672/7935]  loss: 0.29412857      accuracy:  98.566%\n",
      "epoch:  4  batch:  148 [  4736/7935]  loss: 0.01836224      accuracy:  98.543%\n",
      "epoch:  4  batch:  150 [  4800/7935]  loss: 0.05025672      accuracy:  98.562%\n",
      "epoch:  4  batch:  152 [  4864/7935]  loss: 0.09049369      accuracy:  98.540%\n",
      "epoch:  4  batch:  154 [  4928/7935]  loss: 0.08727665      accuracy:  98.519%\n",
      "epoch:  4  batch:  156 [  4992/7935]  loss: 0.12017304      accuracy:  98.498%\n",
      "epoch:  4  batch:  158 [  5056/7935]  loss: 0.03116201      accuracy:  98.477%\n",
      "epoch:  4  batch:  160 [  5120/7935]  loss: 0.02101764      accuracy:  98.496%\n",
      "epoch:  4  batch:  162 [  5184/7935]  loss: 0.01086628      accuracy:  98.495%\n",
      "epoch:  4  batch:  164 [  5248/7935]  loss: 0.02383817      accuracy:  98.514%\n",
      "epoch:  4  batch:  166 [  5312/7935]  loss: 0.07411570      accuracy:  98.494%\n",
      "epoch:  4  batch:  168 [  5376/7935]  loss: 0.19056697      accuracy:  98.475%\n",
      "epoch:  4  batch:  170 [  5440/7935]  loss: 0.05023024      accuracy:  98.493%\n",
      "epoch:  4  batch:  172 [  5504/7935]  loss: 0.04937018      accuracy:  98.492%\n",
      "epoch:  4  batch:  174 [  5568/7935]  loss: 0.03544303      accuracy:  98.491%\n",
      "epoch:  4  batch:  176 [  5632/7935]  loss: 0.01523928      accuracy:  98.509%\n",
      "epoch:  4  batch:  178 [  5696/7935]  loss: 0.09882572      accuracy:  98.508%\n",
      "epoch:  4  batch:  180 [  5760/7935]  loss: 0.02236412      accuracy:  98.507%\n",
      "epoch:  4  batch:  182 [  5824/7935]  loss: 0.01696923      accuracy:  98.523%\n",
      "epoch:  4  batch:  184 [  5888/7935]  loss: 0.01926342      accuracy:  98.539%\n",
      "epoch:  4  batch:  186 [  5952/7935]  loss: 0.10038836      accuracy:  98.538%\n",
      "epoch:  4  batch:  188 [  6016/7935]  loss: 0.00082235      accuracy:  98.554%\n",
      "epoch:  4  batch:  190 [  6080/7935]  loss: 0.10601096      accuracy:  98.536%\n",
      "epoch:  4  batch:  192 [  6144/7935]  loss: 0.00382057      accuracy:  98.535%\n",
      "epoch:  4  batch:  194 [  6208/7935]  loss: 0.00723519      accuracy:  98.534%\n",
      "epoch:  4  batch:  196 [  6272/7935]  loss: 0.00453057      accuracy:  98.549%\n",
      "epoch:  4  batch:  198 [  6336/7935]  loss: 0.01549665      accuracy:  98.564%\n",
      "epoch:  4  batch:  200 [  6400/7935]  loss: 0.01447509      accuracy:  98.562%\n",
      "epoch:  4  batch:  202 [  6464/7935]  loss: 0.05586439      accuracy:  98.561%\n",
      "epoch:  4  batch:  204 [  6528/7935]  loss: 0.01968383      accuracy:  98.560%\n",
      "epoch:  4  batch:  206 [  6592/7935]  loss: 0.00576532      accuracy:  98.574%\n",
      "epoch:  4  batch:  208 [  6656/7935]  loss: 0.00528359      accuracy:  98.588%\n",
      "epoch:  4  batch:  210 [  6720/7935]  loss: 0.00734532      accuracy:  98.571%\n",
      "epoch:  4  batch:  212 [  6784/7935]  loss: 0.00087894      accuracy:  98.585%\n",
      "epoch:  4  batch:  214 [  6848/7935]  loss: 0.01591838      accuracy:  98.598%\n",
      "epoch:  4  batch:  216 [  6912/7935]  loss: 0.08660316      accuracy:  98.582%\n",
      "epoch:  4  batch:  218 [  6976/7935]  loss: 0.13301663      accuracy:  98.581%\n",
      "epoch:  4  batch:  220 [  7040/7935]  loss: 0.05676441      accuracy:  98.580%\n",
      "epoch:  4  batch:  222 [  7104/7935]  loss: 0.04372388      accuracy:  98.578%\n",
      "epoch:  4  batch:  224 [  7168/7935]  loss: 0.01214320      accuracy:  98.591%\n",
      "epoch:  4  batch:  226 [  7232/7935]  loss: 0.03220124      accuracy:  98.603%\n",
      "epoch:  4  batch:  228 [  7296/7935]  loss: 0.01434931      accuracy:  98.616%\n",
      "epoch:  4  batch:  230 [  7360/7935]  loss: 0.02769652      accuracy:  98.614%\n",
      "epoch:  4  batch:  232 [  7424/7935]  loss: 0.00402305      accuracy:  98.613%\n",
      "epoch:  4  batch:  234 [  7488/7935]  loss: 0.01093217      accuracy:  98.624%\n",
      "epoch:  4  batch:  236 [  7552/7935]  loss: 0.00933498      accuracy:  98.623%\n",
      "epoch:  4  batch:  238 [  7616/7935]  loss: 0.00166278      accuracy:  98.634%\n",
      "epoch:  4  batch:  240 [  7680/7935]  loss: 0.03254898      accuracy:  98.620%\n",
      "epoch:  4  batch:  242 [  7744/7935]  loss: 0.00485882      accuracy:  98.631%\n",
      "epoch:  4  batch:  244 [  7808/7935]  loss: 0.00537003      accuracy:  98.630%\n",
      "epoch:  4  batch:  246 [  7872/7935]  loss: 0.00506469      accuracy:  98.641%\n",
      "epoch:  4  batch:  248 [  7935/7935]  loss: 0.00523385      accuracy:  98.626%\n",
      "\n",
      "Duration: 1688 seconds\n"
     ]
    }
   ],
   "source": [
    "train_loss,val_loss = mch.trainModel(model=model,train_dl=train_dl,val_dl=val_dl,criterion=criterion,optim=optimizer,train_samples=7935,batch_size=32,soft_max=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9808efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+GklEQVR4nO3dd3hU1dbA4d9KJ4UakN5r6BghClIEkSqCiKCIqIiAyLWLfl6wy/VyFREVsYsIIop0UASk9ya9l4BITSC0tP39cSYxxJQJmeRMZtb7PHmYzGkrO2TNmT3nrCXGGJRSSnkuH7sDUEoplbc00SullIfTRK+UUh5OE71SSnk4TfRKKeXhNNErpZSH00Sv3I6ILBGRAXbHkZ6IfCUib1zntt1F5KiIxIlIY1fHlskxrzve/CAi/UVkud1xeANN9B5CRA6JSDu740hLRCqLiBERvyzWeUVEvs3PuGwyGhhqjAk1xmyyOxjlXTTRK5U/KgHb7Q5CeSdN9B5ORAJFZIyIHHd8jRGRQMeycBGZLSIxInJWRJaJiI9j2QsickxELojIbhFpm8n+O4vIJhE575iaeCXN4qWOf2McUxY3p9u2A/AScK9j+ZY0iyuJyArH8X8RkfA020WJyEpH3FtEpHUWP39ZEflRRE6JyEERGZZm2SsiMlVEvnEcZ7uIRKZZ3lhENjqWfQ8EZXEcHxF5WUQOi8hJxz6LOMY/DvAFtojI/ky2ry0ivzp+D7tFpJeTY4yItEgzHkdFpH+axcVEZI7jZ1gjItWy+BkyHVfHdNrbIrJWRGJFZIaIFE+z/E7H+MU41q2TZlkFEfnJ8Ts4IyLj0h13tIicc/x+OmYWn8oFY4x+ecAXcAhol8HzrwGrgVJASWAl8Lpj2dvAeMDf8XUrIEAt4ChQ1rFeZaBaJsdtDdTHOmloAPwF3JVmOwP4ZRH3K8C36Z5bAuwHagKFHN+PciwrB5wBOjmOebvj+5IZ7NsH2ACMAAKAqsAB4I40x77i2JevYzxWO5YFAIeBpxxj0xNIAN7I5Od4GNjnOEYo8BMwMc1yA1TPZNsQx3g/BPgBTYDTQF0nxrgicAHo44izBNDIsewr4CzQ1LHfScCUTGLIclwdv4NjQD1HvD+m/N4cv6eLjm38gecdYxHgGNctwHuO7YKAFo7t+jvG9FHHeoOB44DY/ffkaV+2B6BfLvpFZp7o9wOd0nx/B3DI8fg1YEb6BARUB04C7QD/HMYxBnjP8bgy15/oX07z/RBgvuPxC2kTqOO5BcCDGey7GXAk3XMvAl+mOfbCNMsigMuOxy3TJx2sF8nMEv1vwJA039dyJDE/x/dZJfp7gWXpnvsEGOnEGL8ITM9kva+Az9J83wnYlcm6WY4raV5s04xVvCNB/xuYmmaZD9aLQmvgZuBURv8HHIl+X5rvgx3jVDov/1a88UunbjxfWawz0xSHHc8B/BfrzOsXETkgIsMBjDH7gCexEuFJEZkiImXJgIg0E5HFjrflscAgIDyjdXPoRJrHl7DOksGa677HMUUQIyIxQAugTAb7qASUTbfuS8ANWRwnSKwPj8sCx4wjAzmkHcf0Mhpnv3THykwloFm6OO8HSkO2Y1wB68U8M5mNY0YxZDeuR9P9fP6OOK752Y0xyY51yzniO2yMScwuPmPMJcfDzGJU10kTvec7jvVHnKKi4zmMMReMMc8YY6oCXYGnU+bijTHfGWNaOLY1wH8y2f93wEyggjGmCNZUkDiWOVMaNaflU49inXkWTfMVYowZlcm6B9OtG2aM6eTEcf4EyomIpHmuYhbrZzTOiVjTLNk5CvyeLs5QY8xgx/KsxvgokOm8ew44M64V0jyuiPWO5TTpfnbHmFXAOqs/ClSULK68UnlPE71n8ReRoDRffsBk4GURKen4QHME8C2AiHQRkeqOP8zzQBKQJCK1ROQ2sT60vQJcdizLSBhw1hhzRUSaAvelWXYKSMaat87MX0BlcXwI7IRvga4icoeI+Dp+ztYiUj6DddcC58X6YLmQY/16InKTE8dZhZWoh4mIn4j0wJrrzsxk4CkRqSIiocBbwPdZnMmmNRuoKSIPiIi/4+umNB9oZjXGk4B2ItLLEWcJEWnkxDHTc2Zc+4pIhIgEY037TTPGJAFTgc4i0lZE/IFngKtYU11rsV40R4lIiGO/za8jPpULmug9y1yspJzy9QrwBrAe2Ar8AWx0PAdQA1gIxGElto+MMUuAQGAU1tnaCawPcl/K5JhDgNdE5ALWi8jUlAWOt+JvAisc0wFRGWz/g+PfMyKyMbsf0BhzFOjmiOcU1hnjc2Twf9mRhLoCjYCDjp/nM6CIE8eJB3pgzSOfw5pH/ymLTb4AJmJdaXQQ6wXyieyO4zjWBaA90Bvr7PgE1juoQMcqWY3xEay592ewPnjdDDR05rjpYnBmXCdizfufwPpQdZhj291AX+ADrDHuCnQ1xsSn+R1UB44A0VhjqfKRXDsFqZRS/yQiS7A+NP/M7lhUzukZvVJKeThN9Eop5eF06kYppTycntErpZSHc8trW8PDw03lypXtDkMppQqMDRs2nDbGlMxomVsm+sqVK7N+/Xq7w1BKqQJDRDK9c1unbpRSysNpoldKKQ+niV4ppTycW87RK6XyX0JCAtHR0Vy5csXuUFQWgoKCKF++PP7+/k5vo4leKQVAdHQ0YWFhVK5cmWuLdip3YYzhzJkzREdHU6VKFae306kbpRQAV65coUSJEprk3ZiIUKJEiRy/69JEr5RKpUne/V3P78ijEv3Y3/ay7Vis3WEopZRb8ZhEH3Mpnslrj9Dj45V8v+6I3eEopXIgJiaGjz766Lq27dSpEzExMVmuM2LECBYuXHhd+0+vcuXKnD592iX7yi8ek+iLBgcw+4kWNK1cnBd+/IPnp23hSkJmTZGUUu4kq0SflJT13/HcuXMpWrRoluu89tprtGvX7nrDK/A8JtEDlAgN5OuHm/LEbdWZuj6aHh+t5MiZS9lvqJSy1fDhw9m/fz+NGjXiueeeY8mSJbRp04b77ruP+vXrA3DXXXdx4403UrduXSZMmJC6bcoZ9qFDh6hTpw6PPvoodevWpX379ly+fBmA/v37M23atNT1R44cSZMmTahfvz67du0C4NSpU9x+++00adKExx57jEqVKmV75v7uu+9Sr1496tWrx5gxYwC4ePEinTt3pmHDhtSrV4/vv/8+9WeMiIigQYMGPPvssy4dv+x43OWVvj7CM+1r0bhiUZ6cspkuHyzj3V6NaBdxg92hKVVgvDprOzuOn3fpPiPKFmZk17oZLhs1ahTbtm1j8+bNACxZsoS1a9eybdu21MsIv/jiC4oXL87ly5e56aabuPvuuylRosQ1+9m7dy+TJ0/m008/pVevXvz444/07dv3H8cLDw9n48aNfPTRR4wePZrPPvuMV199ldtuu40XX3yR+fPnX/NikpENGzbw5ZdfsmbNGowxNGvWjFatWnHgwAHKli3LnDlzAIiNjeXs2bNMnz6dXbt2ISLZTjW5mked0ad1W+0bmDPsVioUD2bAN+v574JdJCVr7X2lCoqmTZtec6342LFjadiwIVFRURw9epS9e/f+Y5sqVarQqFEjAG688UYOHTqU4b579Ojxj3WWL19O7969AejQoQPFihXLMr7ly5fTvXt3QkJCCA0NpUePHixbtoz69euzcOFCXnjhBZYtW0aRIkUoXLgwQUFBDBgwgJ9++ong4OAcjkbueNwZfVoVigfz4+BbeGXmdj5cvJ/NR2N4v3djwkMDs99YKS+W2Zl3fgoJCUl9vGTJEhYuXMiqVasIDg6mdevWGV5LHhj499+2r69v6tRNZuv5+vqSmJgIWDcj5URm69esWZMNGzYwd+5cXnzxRdq3b8+IESNYu3Ytv/32G1OmTGHcuHEsWrQoR8fLDY89o08R5O/LqLsb8M7dDVh/6Bxdxi5nw+FzdoellEojLCyMCxcuZLo8NjaWYsWKERwczK5du1i9erXLY2jRogVTp04F4JdffuHcuazzRMuWLfn555+5dOkSFy9eZPr06dx6660cP36c4OBg+vbty7PPPsvGjRuJi4sjNjaWTp06MWbMmNQpqvzi0Wf0afW6qQIRZQszZNJG7v1kFS93rsODt+it3kq5gxIlStC8eXPq1atHx44d6dy58zXLO3TowPjx42nQoAG1atUiKirK5TGMHDmSPn368P3339OqVSvKlClDWFhYpus3adKE/v3707RpUwAGDBhA48aNWbBgAc899xw+Pj74+/vz8ccfc+HCBbp168aVK1cwxvDee++5PP6suGXP2MjISJNXjUdiLyXwzA+bWbjzJF0blmVUj/qEBHrN651Smdq5cyd16tSxOwzbXL16FV9fX/z8/Fi1ahWDBw/O9zNvZ2X0uxKRDcaYyIzW97oMVyTYnwkPRPLx7/v53y+72fnnecb3vZHqpULtDk0pZaMjR47Qq1cvkpOTCQgI4NNPP7U7JJfxukQP4OMjPN6mOo0qFGXY5E10G7ec//RsQJcGZe0OTSllkxo1arBp0ya7w8gTHv9hbFaaVw9n9rAW1CodxtDvNvHarB0kJCXbHZZSSrmUVyd6gDJFCjFl4M30v6UyX6w4SJ8JqzkRq40XlFKew+sTPUCAnw+v3FmXsX0as+PP83T5YBkr9xesokVKKZUZTfRp3NmwLDMeb06RQv70/WwNHy/Zn+ObKJRSyt1ook+nxg1hzBjago71y/Cf+bsYOHEDsZcT7A5LKZVOaKh1pdzx48fp2bNnhuu0bt2a7C7VHjNmDJcu/V380Jmyx8545ZVXGD16dK734wqa6DMQGujHuD6NGdElgsW7TnLnuOUuL/CklHKNsmXLplamvB7pE70zZY8LGqcSvYh0EJHdIrJPRIZnsPx+Ednq+FopIg2d3dZdiQgPt6jClIFRXElIovtHK/hh/VG7w1LKI73wwgvX1KN/5ZVX+N///kdcXBxt27ZNLSk8Y8aMf2x76NAh6tWrB8Dly5fp3bs3DRo04N57772m1s3gwYOJjIykbt26jBw5ErAKpR0/fpw2bdrQpk0b4NrGIhmVIc6qHHJmNm/eTFRUFA0aNKB79+6p5RXGjh2bWro4paDa77//TqNGjWjUqBGNGzfOsjSEs7K9jl5EfIEPgduBaGCdiMw0xuxIs9pBoJUx5pyIdAQmAM2c3NatRVYuzuwnbmXY5E08N20rG4+cY2TXugT5+9odmlJ5Z95wOPGHa/dZuj50HJXhot69e/Pkk08yZMgQAKZOncr8+fMJCgpi+vTpFC5cmNOnTxMVFcWdd96ZaemSjz/+mODgYLZu3crWrVtp0qRJ6rI333yT4sWLk5SURNu2bdm6dSvDhg3j3XffZfHixYSHh1+zr8zKEBcrVszpcsgp+vXrxwcffECrVq0YMWIEr776KmPGjGHUqFEcPHiQwMDA1Omi0aNH8+GHH9K8eXPi4uIICgrKyShnyJkz+qbAPmPMAWNMPDAF6JZ2BWPMSmNMSgWg1UB5Z7ctCEqGBTLxkaYMbl2NyWuP0nP8So6e1YYmSrlK48aNOXnyJMePH2fLli0UK1aMihUrYozhpZdeokGDBrRr145jx47x119/ZbqfpUuXpibcBg0a0KBBg9RlU6dOpUmTJjRu3Jjt27ezY0fW55uZlSEG58shg1WQLSYmhlatWgHw4IMPsnTp0tQY77//fr799lv8/Kzz7ubNm/P0008zduxYYmJiUp/PDWf2UA5IO2cRDTTLYv1HgHk53VZEBgIDASpWrOhEWPnLz9eHFzrUpnGFojzzwxa6fLCcMfc2ok3tUnaHppTrZXLmnZd69uzJtGnTOHHiROo0xqRJkzh16hQbNmzA39+fypUrZ1ieOK2MzvYPHjzI6NGjWbduHcWKFaN///7Z7ierK+6cLYecnTlz5rB06VJmzpzJ66+/zvbt2xk+fDidO3dm7ty5REVFsXDhQmrXrn1d+0/hzBl9Ru+RMhwBEWmDlehfyOm2xpgJxphIY0xkyZIlnQjLHu3rlmbW0BaUKRLEQ1+t491fdmtDE6VcoHfv3kyZMoVp06alXkUTGxtLqVKl8Pf3Z/HixRw+fDjLfbRs2ZJJkyYBsG3bNrZu3QrA+fPnCQkJoUiRIvz111/MmzcvdZvMSiRnVoY4p4oUKUKxYsVS3w1MnDiRVq1akZyczNGjR2nTpg3vvPMOMTExxMXFsX//furXr88LL7xAZGRkaqvD3HDmjD4aqJDm+/LA8fQriUgD4DOgozHmTE62LWgqh4cwfUhzXv55G2MX7WOTo6FJ8ZAAu0NTqsCqW7cuFy5coFy5cpQpUwaA+++/n65duxIZGUmjRo2yPbMdPHgwDz30EA0aNKBRo0apJYQbNmxI48aNqVu3LlWrVqV58+ap2wwcOJCOHTtSpkwZFi9enPp8ZmWIs5qmyczXX3/NoEGDuHTpElWrVuXLL78kKSmJvn37EhsbizGGp556iqJFi/Lvf/+bxYsX4+vrS0REBB07dszx8dLLtkyxiPgBe4C2wDFgHXCfMWZ7mnUqAouAfsaYlTnZNiN5WabYlYwxTFl3lJEzthMeGsCH9zehccWs248p5a68vUxxQZLTMsXZTt0YYxKBocACYCcw1RizXUQGicggx2ojgBLARyKyWUTWZ7Xt9f1o7kdE6NO0ItMG34yI0OuTVUxcdUjvplVKuRWvazySV2IuxfPk95tZsvsUdzUqy1s96hMc4JVVoFUBpWf0BYfLz+iVc4oGB/DFgzfx9O01mbHlOHd9uIIDp+LsDkupHHHHEz91rev5HWmidyEfH2FY2xp8/VBTTl24yp3jVjDvjz/tDksppwQFBXHmzBlN9m7MGMOZM2dyfBOVTt3kkWMxlxkyaSNbjsbw6K1VeL5Dbfx99XVVua+EhASio6Ozvb5c2SsoKIjy5cvj7+9/zfPaM9YG5YoWYupjUbw5ZyefLjvIlqOxjLuvMaUK5/52ZqXygr+/P1WqVLE7DJUH9BQzDwX6+fJat3qMubcRfxyLpdPY5aw5cCb7DZVSyoU00eeDuxqX4+fHm1M4yI/7PlvDhKXa0EQplX800eeTWqXDmDG0Oe0jbuCtubsY/O1Gzl/RhiZKqbyniT4fhQX589H9TXi5cx1+3fkX3catYNcJbWiilMpbmujzmYgw4NaqTH40iriridz14Qqmb4q2OyyllAfTRG+TplWKM2dYCxqUL8pT32/h5Z//4Gpikt1hKaU8kCZ6G5UKC+K7Ac14rGVVvl19hF7jV3Es5vrqWiulVGY00dvMz9eHFzvVYXzfJuw/dZEuY5fx+55TdoellPIgmujdRId6ZZg5tDmlwoLo/+Va3l+4l2RtaKKUcgFN9G6kaslQpj9+C3c1Ksd7C/fw8NfrOHcx3u6wlFIFnCZ6NxMc4Me7vRryxl31WLnvDF0+WM7W6Bi7w1JKFWCa6N2QiNA3qhJTB90MQM+PV/HdmiN6N61S6rpoondjjSoUZdYTLWhWtTgvTf+DZ3/YyuV4vQRTKZUzmujdXPGQAL56qCn/aluDnzZF0/2jFRw6fdHusJRSBYgm+gLA10d46vaafNH/Jk6cv0LXD5bzy/YTdoellCogNNEXIG1qlWLW0BZUDg9h4MQNjJq3i8SkZLvDUkq5OU30BUyF4sH8MOhm7mtWkfG/76fv52s4deGq3WEppdyYJvoCKMjfl7e612f0PQ3ZdCSGzmOXsf7QWbvDUkq5KU30BVjPG8szfUhzCgX40nvCaj5fflAvwVRK/YMm+gIuomxhZg5tQZvapXh99g6GfreJuKuJdoellHIjmug9QJFC/kx44EaGd6zNvG1/cue45ez964LdYSml3IQmeg8hIgxqVY1JA6I4fzmBbh+uYMbmY3aHpZRyA5roPczN1UowZ9itRJQpzL+mbOaVmduJT9RLMJXyZproPdANhYOYPDCKR1pU4auVh7h3wir+jNWGJkp5K030Hsrf14d/d4ngw/uasOfEBTqPXc6KfaftDkspZQNN9B6uc4MyzBjaghIhATzw+Ro+XLxPG5oo5WU00XuB6qVC+fnx5nRpUJb/LtjNo9+sJ/ZSgt1hKaXyiSZ6LxES6Mf7vRvx6p11Wbr3FF3GLWPbsVi7w1JK5QNN9F5ERHjwlspMGXgzCYmGHh+vZP62P+0Oq+BIuAwJV+yOQqkc00TvhW6sVIw5w1pQu3QYL/70h07jOCM2GsY1hc/aQrz2A1AFiyZ6L1UiNJBRPRoQezmBMb/tsTsc9xZ3Er7pBpfPwl/bYfbToDWFVAHiVKIXkQ4isltE9onI8AyW1xaRVSJyVUSeTbfskIj8ISKbRWS9qwJXuRdRtjC9m1bkm1WHtWRCZi6dhYnd4fxx6PsjtB4OW6fAhq/sjkwpp2Wb6EXEF/gQ6AhEAH1EJCLdameBYcDoTHbTxhjTyBgTmZtgles9c3tNggN8eW32Dq18md7VCzDpHji9B3p/BxWjoOVzUO02mPc8HN9kd4RKOcWZM/qmwD5jzAFjTDwwBeiWdgVjzEljzDpAJ3sLmBKhgTzZribL9p5m0a6TdofjPhIuw+Q+VjK/5yuo1sZ63scXenwGIaVgaj/rjF8pN+dMoi8HHE3zfbTjOWcZ4BcR2SAiA3MSnMof/W6uRLWSIbw+e4fWxQFIjIepD8Kh5dD9E6jd+drlISWg19dw/k+YPgiSdcyUe3Mm0UsGz+XkPX5zY0wTrKmfx0WkZYYHERkoIutFZP2pU6dysHuVWynlEg6ducRXKw/aHY69kpNg+kDYuwC6vAcN7sl4vfKRcMdb1nrL383fGJXKIWcSfTRQIc335YHjzh7AGHPc8e9JYDrWVFBG600wxkQaYyJLlizp7O6Vi7SuVYo2tUrywW/7vLcHbXIyzBwG26dD+zcg8qGs12/6KNS7Gxa/CQd+z58YlboOziT6dUANEakiIgFAb2CmMzsXkRARCUt5DLQHtl1vsCpvvdwlgssJSfzvl912h5L/jIEFL8Lmb6HVcLjliey3EYGuY6FEDfjxEevKHKXcULaJ3hiTCAwFFgA7ganGmO0iMkhEBgGISGkRiQaeBl4WkWgRKQzcACwXkS3AWmCOMWZ+Xv0wKneqlQyl/y2V+X79Ue8rj7D4TVgzHqIety6hdFZgKNw7EeIvwQ8PQZJej6Dcj7jjJXWRkZFm/Xq95N4OsZcTuG30EqqWDGHqYzcjktFHNB5m+RhYOBKa9LPO0K/nZ/5jmnVWf/NQuONNl4eoVHZEZENml7DrnbHqGkUK+fPsHbVYd+gcs7d6QR2ctZ9aSb5eT+gy5vqSPED9nnDTo7BqHOyY4dIQlcotTfTqH3pFViCiTGHenruTy/FJdoeTd7ZMgbnPQs2O0H28dY18btzxJpS7EX5+HE7vc02MSrmAJnr1D74+wsiuERyPvcKEpQfsDidv7JgJPw+GKq2sG6J8/XO/T79AuOdra19T+1nz9kq5AU30KkPNqpagc/0yfPz7Po7HeFi/2X0LYdrDUC7SKm3gH+S6fRetAHd/Cid3wBwtfqbcgyZ6lanhHWtjDIyat8vuUFzn8EqY0hdK1Yb7f7CumnG16u2g1QuwZTJs/Nr1+1cqhzTRq0xVKB7MYy2rMnPLcdYd8oCaLsc2wqRe1ln3Az9DoaJ5d6xWz1vFz+Y+D8c3591xlHKCJnqVpUGtq1G6cBCvztpesJuK/7UDvu0BwcWsJB8SnrfHSy1+Fg5TH4DL5/L2eEplQRO9ylJwgB8vdqrNtmPnmbYh2u5wrs+Z/TDxLvANhH4zoUhOavLlQkgJ68NZLX6mbKaJXmXrzoZlaVKxKO8s2M2FKwXszs/YaPjmLkhOhH4zoHiV/D1+hZusyy73zIcV7+XvsZVy0ESvsiUijOxal9NxVxm3uABdH57SAvBKDPT9yfoA1g5NB1rFzxa9AQeX2hOD8mqa6JVTGlYoSs8by/PF8oMcPF0AmmNfPvd3C8D7f4CyjeyLJbX4WXXrss7zXnDHsXIrmuiV056/oxYBvj68OWen3aFk7eoF+LanowXgJKsFoN0CQ6GXo/jZNC1+pvKXJnrltFKFgxh6Ww0W7vyLpXvctDnMP1oA3mZ3RH8rVRu6vg9HVsHCV+yORnkRTfQqRx5uUZlKJYJ5ffYOEpPc7CqSa1oAjv9nC0B30OAeuGmAo/iZU20dlMo1TfQqRwL9fHmpUx32noxj0pojdofzt3+0AOxld0SZu+Mtq/jZjMetSz+VymOa6FWOtY+4gebVS/Dur3s4dzHe7nCs69Nn5aAFoN38Aq1pJR9f+P4BLX6m8pwmepVjIsKILnW5cCWB9xbusTeYlBaAm7616ss40wLQHRStaN05e3IHzHlGi5+pPKWJXl2XWqXD6BtViW9XH2bXifP2BZLaAnAItH7RvjiuR412Vk2cLd/Bxm/sjkZ5ME306ro91a4mYUH+vD57B7a0pFw+Bpb+12oBeMdb198dyk6tXnAUP3tOi5+pPKOJXl23YiEBPNWuBiv2neHXHX/l78HXfeZoAXh37loA2s3HF3p86ih+1k+Ln6k8oYle5cr9UZWoUSqUN+bs5GpiPrUd3DLFmteu2RG6f5L7FoB2Cwm3Ppw9fwymD9biZ8rlNNGrXPH39WFE1wiOnL3EF8sP5f0Bd86Cn4dAlZauawHoDio0hfZvwp55sGKM3dEoD6OJXuXarTVK0q7ODYxbtJeT56/k3YH2LYQfHoJyTaD3ZNe2AHQHzR6Dut1h0eta/Ey5lCZ65RIvd65DfFIy7yzYnTcHyI8WgHYTgTs/0OJnyuU00SuXqBwewsMtqjBtQzRbjsa4ducpLQCLlIe+06FQMdfu350EhkGvbyD+opXstfiZcgFN9MplhrapTnhoIK/O2u66yy1P7oRv77ZaAPabAaElXbNfd1aqjlXW+MhK+O1Vu6NRHkATvXKZsCB/nr+jFhuPxDBzy/Hc7/DMfqtxiG+AleTzqwWgO0gpfrbyA+sDaKVyQRO9cqmeN5anfrkivD13F5fiE69/RyktAJMSHC0Aq7osxgLjjregbBPrKiMtfqZyQRO9cikfH2Fk1whOnL/C+CXXmZziTv3dAvABG1sA2s0vEHp9bd0nMLWfFj9T100TvXK5yMrFubNhWT5ZeoCjZ3OYnFJaAMYeg/umQtnGeRNkQVG0onXn7F/bYe6zWvxMXRdN9CpPDO9YGxEYNW+X8xultgDcDX2+g0o3512ABUmN26Hlc7B5EmyaaHc0qgDSRK/yRNmihRjUqhpz/viTNQfOZL9B2haAPb90rxaA7qD1cKjaBuY8C39usTsaVcBoold55rGW1ShbJIhXZ+0gKTmLKYekhL9bAN71MdTpkn9BFhQ+vnD3Z2mKn8XYHZEqQDTRqzxTKMCXFzvVYcef55m6/mjGKyUnwU8pLQDfhYb35m+QBUlK8bPYaPhZi58p52miV3mqS4My3FS5GKMX7Cb2crq7PFNbAP4Et78OkQ/bE2RBklL8bPdcWPm+3dGoAkITvcpTIsLIrnU5eymeD37b+/cCY2DBS1YLwJbPQ/Nh9gVZ0KQUP/vtNTi4zO5oVAHgVKIXkQ4isltE9onI8AyW1xaRVSJyVUSezcm2yvPVK1eEeyMr8NXKQ+w/FWc9ufgtWPOx1QKwzUv2BljQpBQ/K17Nqodz4YTdESk3l22iFxFf4EOgIxAB9BGRiHSrnQWGAaOvY1vlBZ5pX4sgf1/enLMTVrwPS9+Bxg8U3BaAdgsMg3snQnycVbo5KRd3ISuP58wZfVNgnzHmgDEmHpgCdEu7gjHmpDFmHZC+1F622yrvUDIskGFtq1Nm73fw6wio2wO6vq9JPjdK1bHGUIufqWw4k+jLAWkvmYh2POcMp7cVkYEisl5E1p86dcrJ3auC5OGwtbzu/yWrfG8iodv4gt8C0B006AWRj8DKsbBztt3RKDflTKLP6JTL2fuwnd7WGDPBGBNpjIksWdILStF6m52z8Jv5ODGlmtH/4uN8s9YF1S2VpcPbjuJng7X4mcqQM4k+GqiQ5vvygLN/pbnZVnmKfb9ZHxqWa0KxR6bRrGY5xizcw5m4q3ZH5hlSip+Jj3XjWcJluyNSbsaZRL8OqCEiVUQkAOgNzHRy/7nZVnmCw6tgyv0QXgvu/wEJDGNElzpcik/if7/usTs6z5Fa/OwPq0yCUmlkm+iNMYnAUGABsBOYaozZLiKDRGQQgIiUFpFo4GngZRGJFpHCmW2bVz+McjPHN8F3jhaAD/zdArB6qTAeiKrElLVH2HH8vM1BepCa7R3Fz76Fjd/YHY1yI+Kylm8uFBkZadavX293GCo3Tu6ELztBQCg8PP8f3aFiLyXQevRiapUOY/KjUYhefeMayUnwbQ/rndSAhVCmgd0RqXwiIhuMMZEZLdM7Y5XrnT1gdYfyDYAHM24BWCTYn6fb12L1gbPM36Y3/LiMjy/c/TkEl4CpD2jxMwVooleuFnsMvu4GSfHQ7+csWwD2uakCtUuH8ebcnVxJSMq/GD1dSLj14WxstNWG0A3ftav8pYleuc4/WgDWyXJ1P18fRnSJIPrcZT5bdiB/YvQWFZpC+zdg9xzrTmTl1TTRK9dIbQEYnaMWgLdUD6dD3dJ8uHg/J2Kv5HGQXqbZIIi4y7pr9tByu6NRNtJEr3LvahxMusdqAdh7Uo5bAL7UqQ5JyYZ35ueg7aDKXmrxs6pWPRwtfua1NNGr3Em4AlP6wLGN0PMLqN42x7uoWCKYAbdW4adNx9h45FweBOnFggpDL0fxs2kPa/EzL6WJXl2/pAT44UE4uNTRArDrde9qSJvqlAoL5NVZO0jOqu2gyrkbIqDLGDi8Aha9Znc0ygaa6NX1SWkBuGc+dP5frlsAhgb68UKH2mw5GsP0TcdcFKRK1fBeq4PXivdh1xy7o1H5TBO9yjljYNa/HC0AX4ObBrhkt90bl6NhhaL8Z/4uLl7VKQaX6zDK+pB8+mDrXgflNTTRq5xJbQE40brdvvm/XLZrHx9hZNcITl64ykdL9rlsv8rBLxDu+dr6kPb7flr8zItoolc5s+RtWP0RNBsMbf7P5btvUrEY3RuX49NlBzly5pLL9+/1ilX6u/jZXC1+5i000SvnrRgLv/8HGvfN0xaAL3Soja8Ib83dmSf793o128Otz1qN2TdOtDsalQ800SvnrP8Cfv031O0OXceCT9791yldJIjH21Rj/vYTrNx3Os+O49XavARVWlln9X9utTsalcc00avsbfkeZj8NNe6A7hPypQXggFurUr5YIV6bvYPEpOQ8P57XSSl+Vqg4TO2nxc88nCZ6lbWds60WdZVbWIWy/ALy5bBB/r78X6c67Dpxgcnrjma/gcq50JJwz1cQexRmPK7FzzyYJnqVuf2LYNpD1iV5fSaDf6F8PXyHeqWJqlqcd3/ZTeylhHw9tteo2Axufx12zbYajCuPpIleZezwKph8H4TXhL7TIDAs30MQEUZ0qUvs5QTG/KZtB/NM1GCr+NnCV+HQCrujUXlAE736p9QWgOWuaQFoh4iyhendtCLfrDrM3r8u2BaHR0stflbFegenxc88jiZ6da2Tu2BiDwgqCv1mQGgpuyPimdtrEhzgy2uzd+COrS89QlBh6PUNXDmvxc88kCZ69bezB6zGIb7+VneoIuXtjgiAEqGBPNmuJsv2nmbRrpN2h+O5bqgLXcc4ip+9bnc0yoU00StL7DErySddtc7kS1SzO6Jr9Lu5EtVKhvDGnJ3EJ+rllnmmYW+48SFYMQZ2zbU7GuUimujV3y0AL52Dvtm3ALSDv68P/+4SwcHTF/l65SG7w/FsHUZBmUYwfZAWP/MQmui9XdoWgPdPhXJN7I4oU61rlaJNrZKM/W0vpy5ctTscz+UfZM3Xi1g3U2nxswJPE703u6YF4LdQ6Ra7I8rWy10iuJyQxP9+2W13KJ6tWCXoMQFO/AFzn7M7GpVLmui91cldMPGuNC0A29kdkVOqlQyl/y2V+X79UbYdi7U7HM9W8w5H8bOJVgE0VWBpovc2Vy/Agv+D8c3h9B7o+XmuWgDa4Ym2NSgeHMCrs7br5ZZ5rc1LUKUlzHlGi58VYJrovYUxsPUH+CASVo2DRvfBExutapQFTJFC/jx7Ry3WHTrH7K1/2h2OZ/Pxhbu/sG6am9oPrui7qIJIE703+GsHfNUFfhoAYaVhwG/WnZAh4XZHdt16RVYgokxhRs3bxeX4JLvD8Wxpi5/9PESLnxVAmug92ZVYmP8ijG8BJ7dDl/fg0UVQPtLuyHLN19F28FjMZSYs1UsA81zFKKs/8K7ZsPIDu6NROaSJ3hMZA1umWNM0qz+GJv2saZrIh/Ollnx+aVa1BJ3rl+Hj3/dxPEYvAcxzUUMgohssfEWLnxUwmug9zYk/4MuOMP0xKFrBOoPvOgaCi9sdWZ4Y3rE2xsCoebvsDsXzicCd49IUP/vL7oiUkzTRe4rLMTD3efikJZzabbX7e2ShW98A5QoVigfzWMuqzNxynHWHztodjufT4mcFkib6gi45GTZNgnGRsHaCNT3zxAa48cE87evqTga1rkbpwkG8NmsHycn6QWGeu6Gu9XnP4eVa/KyA8I5M4Kn+3AJf3AEzhkCxyjBwCXT+n8dO02QmOMCPFzvV5o9jsUzbGG13ON6hUR+4sb8WPysgNNEXRJfPWTewTGhtFZ3q9iE8/AuUbWR3ZLa5s2FZmlQsyjvzd3PhirYdzBcd/gNlGjqKnx20OxqVBU30BUlyMmycCB/cCOu/gJsGwBProXFfr5mmyYyIMLJrXU7HXWXc4n12h+Md/lH87IrdEalMOJUdRKSDiOwWkX0iMjyD5SIiYx3Lt4pIkzTLDonIHyKyWUTWuzJ4r3J8E3x+O8wcCiVqwMDfodN/bW3z524aVihKzxvL88Xygxw8fdHucLxDscqO4mdbYZ4WP3NX2SZ6EfEFPgQ6AhFAHxGJSLdaR6CG42sg8HG65W2MMY2MMQX/Tp38dukszHoSJrSBmCNw13h4eD6UaWB3ZG7p+TtqEeDrw5tzdtodiveoeQfc+gxs/Ma6MEC5HWfO6JsC+4wxB4wx8cAUoFu6dboB3xjLaqCoiJRxcazeJTkZNnxlTdNs/AaaDbKmaRr1sd4qqwyVKhzE0NtqsHDnXyzbe8rucLxHm/9zFD972rqXQ7kVZxJ9OeBomu+jHc85u44BfhGRDSIyMLODiMhAEVkvIutPnfLyP9DoDfBZW5j1LyhZGwYtg46jIKiI3ZEVCA+3qEylEsG8NmsHiUnadjBfaPEzt+ZMos/o9DH9xcpZrdPcGNMEa3rncRFpmdFBjDETjDGRxpjIkiVLOhGWB7p4BmY+YSX588egx6fw0FzrumXltEA/X17qVIe9J+OYtOaI3eF4j9CS0PNLOHcYZjyuxc/ciDOJPhqokOb78sBxZ9cxxqT8exKYjjUVpNJKToJ1n8MHTaw5zpsfh6HroUEvnaa5Tu0jbqB59RK8++sezl2Mtzsc71HpZqv42c5ZVjls5RacSfTrgBoiUkVEAoDewMx068wE+jmuvokCYo0xf4pIiIiEAYhICNAe2ObC+Au+o+vg0zbW3Gbp+jB4BdzxpnWrubpuIsKILnW5cCWB9xbusTsc73Lz41DnTvh1pBY/cxPZJnpjTCIwFFgA7ASmGmO2i8ggERnkWG0ucADYB3wKDHE8fwOwXES2AGuBOcaY+S7+GQqmi6ett7eft4O4k3D35/DgLChVx+7IPEat0mH0jarEt6sPs/vEBbvD8R4i1k18xSpb7SrnPgcXTtgdlVcTd2zFFhkZadav99BL7pOTrJudFr0O8Ret0q+tnofAMLsj80jnLsbTevQS6pUrzLePNEN0Kiz/XDgBS962+s36+EPTR6HFU15XoiO/iMiGzC5h9+7bKfPbkTUwoRXMfRbKNILBK6H965rk81CxkACealeDFfvO8OsOLaubr8JKQ9f3Yeg6q479yg9gTANY/JZelZPPNNHnh7iTMH0wfNHeugHqnq+g3wwoWcvuyLzC/VGVqFEqlDfm7ORqorYdzHfFq0KPT2DIaqh+G/z+HyvhL3vXeler8pwm+ryUlAirx1s3Pf3xg/W29fG1VkNunULIN/6+PozoGsGRs5f4Yvkhu8PxXqVqW7VxHlsKFZrBb6/C+w2tLmhaJydPaaLPK4dXWtM081+werQOWQXtXoHAULsj80q31ihJuzo3MG7RXk6e16RiqzIN4f6pVsXVUnVg/nDr0uL1X0KSVh7NC5roXe3CCfhpoNXO70os9JoIfX+C8Bp2R+b1Xu5ch/ikZN5ZsNvuUBRAxWbWlWb9ZkLhsjD7SauBzpYp1kULymU00btKUgKs+tBqyL19Otz6rDVNE3GnTtO4icrhITzcogrTNkSz5WiM3eGoFFVbwSO/wn1TrQsTpj8GH90M23+2aj6pXNNE7wqHlsP4W2HBS1AxyvrQqe2/ISDY7shUOkPbVCc8NJBXZ23HHS8t9loiVhXMgUvhnq+t53540Jr+3LNAyynkkib63Dj/J0x7BL7qbF090Ps7uP8HKFHN7shUJsKC/Hn+jlpsPBLDzC3pK3ko2/n4QN27rM+0un8CV8/Dd73g8/Zw4He7oyuwNNFfj6QEWDHWmk/cOQtavQCPr4HanXWapgDoeWN56pcrwttzd3EpPtHucFRGfHyhYW+r5lOXMVaRv2/uhK+7wtG1dkdX4Giiz6kDv8PHzeHXf0PlFvD4amjzkk7TFCA+PsLIrhGcOH+F8Uv22x2OyoqvP0Q+BE9shA6j4OROq9PapF7w5xa7oyswNNE7K/YY/NDfOqtIvAJ9psB931s3g6gCJ7Jyce5sWJZPlh4g+twlu8NR2fEPgqjB8K8t0HYkHF0Dn7S0at+f3GV3dG5PE312EuNh+Xsw7ibYPQ9av2RN09TqaHdkKpeGd6yNCLw9TxNFgREQArc+DU9utaZM9/0GH98MPz0GZw/YHZ3b0kSflf2L4ONbYOErULW1leBbvwD+heyOTLlA2aKFGNSqGnO2/smaA2fsDkflRFARa8r0X1vh5qGwY4Z1MjbrXxAbbXd0bkcTfUZijsL3D8DE7pCcCPf9AH2+s8quKo/yWMtqlC0SxKuzdpCUrJfwFTghJazCgP/aDJEPW417xjaBecOtGlMK0ER/rcSrsHQ0fNgU9v4KbV62romv2d7uyFQeKRTgy4ud6rDjz/NMXX80+w2UeworDZ3+C8M2Wp3Z1k6w6ugsfMUqJOjltB59ir0LYd7zcHY/1O4CHd6GohXzNwZlC2MMvT5ZxYFTF1n0bGuKFPK3OySVW2f2W7Xw/5hm3W1781Drw1wP7tym9eizcu4wTLkfJt1tfd/3R+g9SZO8FxERRnaty9lL8Xzw2167w1GuUKIa3P2Z1ZqzSktY8pZ1hr/ifYj3vqusvDfRJ1yB39+xpmn2L4K2I6y78aq3szsyZYN65Ypwb2QFvlp5iP2n4uwOR7nKDXWtE7dHF0O5JvDrCBjbCNZMsKZqvYR3Jvo9C+CjKFj8plVf4/G1cOsz4Bdod2TKRs+0r0WQvy9vztlpdyjK1co1sd6tPzQPSlSHec9ZfSI2fmP1jfBw3pXozx6E73pbtTN8/OCBn61GCEUr2B2ZcgMlwwIZ1rY6i3adZPFuvWLDI1W6BfrPsf72Q0vBzCfgw5tg6w8eXRrZOxJ9wmVY/DZ82AwOLoV2r1r9Wqu1sTsy5Wb631KFKuEhvD57BwlJWiLXI4lYf/sDfoPek8E/GH4aYJU22TnLIytlen6i3z3PSvC/j7KKjg1dBy2eBL8AuyNTbijAz4eXO9fhwKmLfLPqsN3hqLwkArU7wWPLoOcX1j0z3/eFCa2tq/A8KOF7bqI/s98qfDS5t3Una7+ZcM+XUKSc3ZEpN3db7VK0rFmSMQv3cCbOez6w81o+PlDvbuuemW4fweWz1lV4X3a0ek14AM9L9PGXYNEb1oeth1dA+zdg0HKri41SThARRnSpw6X4JN79dY/d4aj84usHje+HoRug8//g3CGr18Q3d0F0Pt/X42Kek+iNgZ2zrWmapf+FiG5WLetbnrBKnSqVA9VLhfFAVCUmrz3CjuPn7Q5H5Se/ALhpAAzbBO3fhBNb4bO21oUcJ/6wO7rr4jmJ/koszBgCgaHWp+p3fwaFy9gdlSrAnmpXkyKF/HlttrYd9Er+heCWoVZp5NtehsMrYXwLq1z5qYL1Ts9zEn2holaCf2yp1RBEqVwqEuzP0+1rsfrAWeZvO2F3OMougWHQ8jl4cgvc+izs+QU+agY/D7GmdwoAz0n0AKXr6zSNcqk+N1Wgdukw3py7kysJnnudtXJCoWLQ9t9WLfyoIVYdnQ9uhNlPwXn37j/sWYleKRfz8/VhRJcIos9d5vPlB+0OR7mDkHC4402rNHKTB2HjRBjbGBb8H8Sdsju6DGmiVyobt1QPp0Pd0ny4eB8nYq/YHY5yF4XLQpd34Yn11uWZqz+yCqf99hpcPmd3dNfQMsVKOeHImUu0e/d3igb7U6lEMOGhgYSHBlIyLNDxOIDwsEBKOp4L8ve1O2SV307vhcVvwfafILCIdcVf1CBrjj8fZFWmWBO9Uk6av+0Es7Ye5/SFq5yOu8rpuHhiLydkuG5ooB/hoQFpXgjSvjD8/aIQHhpIoQB9UfAoJ7ZZBRN3z4XgEtDiabjpkTxvQaqJXqk8cjUxiTNx8Y7Ef5XTF+I5FXeVU6kvBimPs39RuPYdQiDhYX8/py8KBVD0Blj0OhxYDKGloeWz1px+HpVf0USvlBuIT0zmzMU0LwKOF4XT17wwWC8aMZcyflEICfD9x4tBydCg1BeF8NBASoXpi0J+S042XEpI4uLVROKuJhJ3JTH1cdDxVdTe/j6lYjYRG1iGxaUfZlVIWy4kQNzVJOKuJHDxahJxVxMJC/Jj/pMtryuGrBK9X65+OqWU0wL8fChTpBBlimT/Fj7lReH0BSvxn0r/YnDhKvtPxbH6YNYvCuGOpF8yzTuEtO8cUp4PDvC+VBCfmJyajC/GpyTmpGuS9MWricSlLLtiLb/oWD9tQr+UkJRFDbQA4Fla+WzlmeSp3HX4TRrzJROD+rA+tA0hQf6EhwZa7+zC8qYnhlNn9CLSAXgf8AU+M8aMSrdcHMs7AZeA/saYjc5smxE9o1fKefGJyZy9GJ/6zuBUmmmk0+mmkc458aKQ2WcLdr8oGGO4nJDkSMBJjsSbeE3iTZ+Qr03SKQnd2kd8onNlqAP8fAgN9CMk0JeQAD/HYz9Cg/wIDXA8DvT9+7lAP0JSn7e2S3m+kJ8PsnuuNYd/cgeUqgu3/R/U6mRV08yFXE3diIgvsAe4HYgG1gF9jDE70qzTCXgCK9E3A943xjRzZtuMaKJXKm8kJCWnfqZwKu6q44Pl+GteDFJeHDJ7UQi+Zvoog3cJaT5bCPD1sRJrfLqz5GuSdNI/n49Pk6yv/J3Mk52caQ4JsJJrarJNk5BTn78mGackaSthp03oAX55cBV6chJsn25dpXN2P5S70SqzULXNdSf83E7dNAX2GWMOOHY2BegGpE3W3YBvjPWqsVpEiopIGaCyE9sqpfKJv68PpYsEUbpIULbrJiRZ7xRSXgRSPlRO+2Jw8PRF1h06x9mL8bmMS1ITbJgjERcp5E+5okGpSTrl+dQzaEcyviahB/oR7O+Lj0/uzo7znI8v1O8JEXfBlsnw+39gYneo1NxqeejiK3ScSfTlgKNpvo/GOmvPbp1yTm6rlHJD/r4+3FA4iBsKZ/+ikOh4UTiZ7kPlqwnJhAT6pkvSfumStC+Bfl76wbGvHzR5ABr0svrXntiaJ5dhOpPoM3ppTP8GKrN1nNnW2oHIQGAgQMWKFZ0ISynlLvx8fShVOIhSTrwoqAz4BULTR/Ns985MPkUDabtnlwfSV/DJbB1ntgXAGDPBGBNpjIksWbKkE2EppZRyhjOJfh1QQ0SqiEgA0BuYmW6dmUA/sUQBscaYP53cVimlVB7KdurGGJMoIkOBBViXSH5hjNkuIoMcy8cDc7GuuNmHdXnlQ1ltmyc/iVJKqQzpnbFKKeUBsrq8UssUK6WUh9NEr5RSHk4TvVJKeThN9Eop5eHc8sNYETkFHL7OzcOB0y4Mx1U0rpzRuHJG48oZT4yrkjEmw5uQ3DLR54aIrM/sk2c7aVw5o3HljMaVM94Wl07dKKWUh9NEr5RSHs4TE/0EuwPIhMaVMxpXzmhcOeNVcXncHL1SSqlreeIZvVJKqTQ00SullIcrkIleRDqIyG4R2SciwzNYLiIy1rF8q4g0cZO4WotIrIhsdnyNyKe4vhCRkyKyLZPldo1XdnHZNV4VRGSxiOwUke0i8q8M1sn3MXMyrnwfMxEJEpG1IrLFEderGaxjx3g5E5ct/8ccx/YVkU0iMjuDZa4dL2NMgfrCKne8H6gKBABbgIh063QC5mF1uIoC1rhJXK2B2TaMWUugCbAtk+X5Pl5OxmXXeJUBmjgeh2E1uHeH/2POxJXvY+YYg1DHY39gDRDlBuPlTFy2/B9zHPtp4LuMju/q8SqIZ/SpzcqNMfFASsPxtFKblRtjVgMpzcrtjssWxpilwNksVrFjvJyJyxbGmD+NMRsdjy8AO7H6H6eV72PmZFz5zjEGcY5v/R1f6a/ysGO8nInLFiJSHugMfJbJKi4dr4KY6DNrRJ7TdeyIC+Bmx1vJeSJSN49jcpYd4+UsW8dLRCoDjbHOBtOydcyyiAtsGDPHNMRm4CTwqzHGLcbLibjAnv9jY4DngeRMlrt0vApios9Ns/K85MwxN2LVo2gIfAD8nMcxOcuO8XKGreMlIqHAj8CTxpjz6RdnsEm+jFk2cdkyZsaYJGNMI6y+0E1FpF66VWwZLyfiyvfxEpEuwEljzIasVsvgueser4KY6HPTrNzWuIwx51PeShpj5gL+IhKex3E5w47xypad4yUi/ljJdJIx5qcMVrFlzLKLy+7/Y8aYGGAJ0CHdIlv/j2UWl03j1Ry4U0QOYU3x3iYi36Zbx6XjVRATfW6aldsal4iUFhFxPG6KNf5n8jguZ9gxXtmya7wcx/wc2GmMeTeT1fJ9zJyJy44xE5GSIlLU8bgQ0A7YlW41O8Yr27jsGC9jzIvGmPLGmMpYeWKRMaZvutVcOl7ZNgd3NyYXzcrdIK6ewGARSQQuA72N4yP2vCQik7GuLggXkWhgJNYHU7aNl5Nx2TJeWGdcDwB/OOZ3AV4CKqaJzY4xcyYuO8asDPC1iPhiJcqpxpjZdv9NOhmXXf/H/iEvx0tLICillIcriFM3SimlckATvVJKeThN9Eop5eE00SullIfTRK+UUh5OE71SSnk4TfRKKeXh/h9WRjpgzjAXHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mch.visualiziseTrainResults(train_losses=train_loss,test_losses=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cef499ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mch.saveModel(model=model,filename=\"YVMweights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
